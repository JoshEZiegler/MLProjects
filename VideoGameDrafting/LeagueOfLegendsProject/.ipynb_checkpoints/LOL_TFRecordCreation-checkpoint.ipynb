{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T21:42:28.824030Z",
     "start_time": "2019-11-06T21:42:24.293936Z"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import pylab as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "from IPython import display\n",
    "from riotwatcher import RiotWatcher\n",
    "import requests\n",
    "\n",
    "api_file = os.path.join('..','..','..','apikeys','LOL_api_key.txt')\n",
    "with open(api_file, 'r') as fin:\n",
    "    watcher = RiotWatcher(fin.readline())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data and put it into a TFRecords file\n",
    "Do this to nicely handle the features that is a numpy array (blue_champs and red_champs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T23:10:39.549250Z",
     "start_time": "2019-11-08T23:10:39.532988Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LOL_data/challenger_tier/V9.10/saved2019-05-28.csv', 'LOL_data/masters_tier/V9.10/saved2019-05-17.csv']\n"
     ]
    }
   ],
   "source": [
    "#get all files in challenger_tier data folder, then sort by date\n",
    "files = glob.glob(os.path.join('LOL_data','*','V9.10','*.csv'))\n",
    "#files.sort(key=os.path.getmtime)\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T23:21:54.579907Z",
     "start_time": "2019-11-08T23:21:52.267026Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOL_data/challenger_tier/V9.10/saved2019-05-28.csv\n",
      "LOL_data/masters_tier/V9.10/saved2019-05-17.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blue_win</th>\n",
       "      <th>blue_gold</th>\n",
       "      <th>red_gold</th>\n",
       "      <th>blue_tower_kills</th>\n",
       "      <th>red_tower_kills</th>\n",
       "      <th>blue_inhibitor_kills</th>\n",
       "      <th>red_inhibitor_kills</th>\n",
       "      <th>blue_dragon_kills</th>\n",
       "      <th>red_dragon_kills</th>\n",
       "      <th>blue_baron_kills</th>\n",
       "      <th>...</th>\n",
       "      <th>red_champs0</th>\n",
       "      <th>blue_champs1</th>\n",
       "      <th>red_champs1</th>\n",
       "      <th>blue_champs2</th>\n",
       "      <th>red_champs2</th>\n",
       "      <th>blue_champs3</th>\n",
       "      <th>red_champs3</th>\n",
       "      <th>blue_champs4</th>\n",
       "      <th>red_champs4</th>\n",
       "      <th>skill_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>441677.000000</td>\n",
       "      <td>441677.000000</td>\n",
       "      <td>441677.000000</td>\n",
       "      <td>441677.000000</td>\n",
       "      <td>441677.000000</td>\n",
       "      <td>441677.000000</td>\n",
       "      <td>441677.000000</td>\n",
       "      <td>441677.000000</td>\n",
       "      <td>441677.000000</td>\n",
       "      <td>441677.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>441677.000000</td>\n",
       "      <td>441677.000000</td>\n",
       "      <td>441677.000000</td>\n",
       "      <td>441677.000000</td>\n",
       "      <td>441677.000000</td>\n",
       "      <td>441677.000000</td>\n",
       "      <td>441677.000000</td>\n",
       "      <td>441677.000000</td>\n",
       "      <td>441677.000000</td>\n",
       "      <td>441677.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.493564</td>\n",
       "      <td>50667.496270</td>\n",
       "      <td>50894.768367</td>\n",
       "      <td>5.239075</td>\n",
       "      <td>5.249990</td>\n",
       "      <td>0.856535</td>\n",
       "      <td>0.857602</td>\n",
       "      <td>1.333948</td>\n",
       "      <td>1.499933</td>\n",
       "      <td>0.424299</td>\n",
       "      <td>...</td>\n",
       "      <td>127.025784</td>\n",
       "      <td>128.486014</td>\n",
       "      <td>128.615937</td>\n",
       "      <td>128.043627</td>\n",
       "      <td>127.839944</td>\n",
       "      <td>128.491395</td>\n",
       "      <td>128.608868</td>\n",
       "      <td>127.264297</td>\n",
       "      <td>126.917019</td>\n",
       "      <td>0.724167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.499959</td>\n",
       "      <td>15476.016762</td>\n",
       "      <td>15707.437316</td>\n",
       "      <td>3.728810</td>\n",
       "      <td>3.767128</td>\n",
       "      <td>1.113665</td>\n",
       "      <td>1.109356</td>\n",
       "      <td>1.214319</td>\n",
       "      <td>1.268132</td>\n",
       "      <td>0.613052</td>\n",
       "      <td>...</td>\n",
       "      <td>130.100459</td>\n",
       "      <td>130.826929</td>\n",
       "      <td>131.269630</td>\n",
       "      <td>130.474368</td>\n",
       "      <td>130.717533</td>\n",
       "      <td>130.736454</td>\n",
       "      <td>131.399606</td>\n",
       "      <td>130.096694</td>\n",
       "      <td>129.770730</td>\n",
       "      <td>0.446933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3313.000000</td>\n",
       "      <td>3345.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>40860.000000</td>\n",
       "      <td>40873.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>51309.000000</td>\n",
       "      <td>51651.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>60938.000000</td>\n",
       "      <td>61422.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>145.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>145.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>136791.000000</td>\n",
       "      <td>133619.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>555.000000</td>\n",
       "      <td>555.000000</td>\n",
       "      <td>555.000000</td>\n",
       "      <td>555.000000</td>\n",
       "      <td>555.000000</td>\n",
       "      <td>555.000000</td>\n",
       "      <td>555.000000</td>\n",
       "      <td>555.000000</td>\n",
       "      <td>555.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            blue_win      blue_gold       red_gold  blue_tower_kills  \\\n",
       "count  441677.000000  441677.000000  441677.000000     441677.000000   \n",
       "mean        0.493564   50667.496270   50894.768367          5.239075   \n",
       "std         0.499959   15476.016762   15707.437316          3.728810   \n",
       "min         0.000000    3313.000000    3345.000000          0.000000   \n",
       "25%         0.000000   40860.000000   40873.000000          2.000000   \n",
       "50%         0.000000   51309.000000   51651.000000          5.000000   \n",
       "75%         1.000000   60938.000000   61422.000000          9.000000   \n",
       "max         1.000000  136791.000000  133619.000000         15.000000   \n",
       "\n",
       "       red_tower_kills  blue_inhibitor_kills  red_inhibitor_kills  \\\n",
       "count    441677.000000         441677.000000        441677.000000   \n",
       "mean          5.249990              0.856535             0.857602   \n",
       "std           3.767128              1.113665             1.109356   \n",
       "min           0.000000              0.000000             0.000000   \n",
       "25%           2.000000              0.000000             0.000000   \n",
       "50%           5.000000              0.000000             0.000000   \n",
       "75%           9.000000              1.000000             1.000000   \n",
       "max          15.000000             13.000000            12.000000   \n",
       "\n",
       "       blue_dragon_kills  red_dragon_kills  blue_baron_kills  ...  \\\n",
       "count      441677.000000     441677.000000     441677.000000  ...   \n",
       "mean            1.333948          1.499933          0.424299  ...   \n",
       "std             1.214319          1.268132          0.613052  ...   \n",
       "min             0.000000          0.000000          0.000000  ...   \n",
       "25%             0.000000          0.000000          0.000000  ...   \n",
       "50%             1.000000          1.000000          0.000000  ...   \n",
       "75%             2.000000          2.000000          1.000000  ...   \n",
       "max             7.000000          9.000000          5.000000  ...   \n",
       "\n",
       "         red_champs0   blue_champs1    red_champs1   blue_champs2  \\\n",
       "count  441677.000000  441677.000000  441677.000000  441677.000000   \n",
       "mean      127.025784     128.486014     128.615937     128.043627   \n",
       "std       130.100459     130.826929     131.269630     130.474368   \n",
       "min         1.000000       1.000000       1.000000       1.000000   \n",
       "25%        39.000000      39.000000      39.000000      39.000000   \n",
       "50%        84.000000      85.000000      85.000000      85.000000   \n",
       "75%       145.000000     154.000000     154.000000     154.000000   \n",
       "max       555.000000     555.000000     555.000000     555.000000   \n",
       "\n",
       "         red_champs2   blue_champs3    red_champs3   blue_champs4  \\\n",
       "count  441677.000000  441677.000000  441677.000000  441677.000000   \n",
       "mean      127.839944     128.491395     128.608868     127.264297   \n",
       "std       130.717533     130.736454     131.399606     130.096694   \n",
       "min         1.000000       1.000000       1.000000       1.000000   \n",
       "25%        39.000000      39.000000      39.000000      39.000000   \n",
       "50%        85.000000      85.000000      85.000000      85.000000   \n",
       "75%       150.000000     154.000000     154.000000     150.000000   \n",
       "max       555.000000     555.000000     555.000000     555.000000   \n",
       "\n",
       "         red_champs4    skill_level  \n",
       "count  441677.000000  441677.000000  \n",
       "mean      126.917019       0.724167  \n",
       "std       129.770730       0.446933  \n",
       "min         1.000000       0.000000  \n",
       "25%        39.000000       0.000000  \n",
       "50%        85.000000       1.000000  \n",
       "75%       145.000000       1.000000  \n",
       "max       555.000000       1.000000  \n",
       "\n",
       "[8 rows x 23 columns]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lol_df = None\n",
    "for filename in files[-2:]:\n",
    "    print(filename)\n",
    "    tier = filename[9:-31]\n",
    "    if tier=='challenger':\n",
    "        tier_num=0\n",
    "    elif tier=='masters':\n",
    "        tier_num=1\n",
    "    else:\n",
    "        raise KeyError\n",
    "    \n",
    "    if type(lol_df)==None:\n",
    "        lol_df = pd.read_csv(filename, usecols=range(1,24))\n",
    "        lol_df['skill_level'] = tier_num\n",
    "    else:\n",
    "        new_df = pd.read_csv(filename,usecols=range(1,24))\n",
    "        new_df['skill_level'] = tier_num\n",
    "        lol_df = pd.concat([lol_df, new_df],ignore_index=True)\n",
    "\n",
    "lol_df = lol_df.reindex(np.random.permutation(lol_df.index))\n",
    "lol_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T23:23:49.378785Z",
     "start_time": "2019-11-08T23:23:49.367035Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lol_df['skill_level'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T22:15:35.061537Z",
     "start_time": "2019-11-06T22:15:35.048127Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144\n"
     ]
    }
   ],
   "source": [
    "champfile=os.path.join('lol_data','version9.10.1_champion.json')\n",
    "with open(champfile,'r') as fin:\n",
    "    champdata=json.load(fin)\n",
    "champ_vocab=[]\n",
    "for name,data in champdata['data'].items():\n",
    "    champ_vocab.append(data['key'])\n",
    "champ_vocab = [int(i) for i in champ_vocab]\n",
    "print(len(champ_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T22:15:39.028566Z",
     "start_time": "2019-11-06T22:15:37.209623Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_style('ticks')\n",
    "champ_sum = np.concatenate((lol_df['blue_champs0'],lol_df['blue_champs1'],lol_df['blue_champs2'],\n",
    "            lol_df['blue_champs3'],lol_df['blue_champs4'],lol_df['red_champs0'],\n",
    "            lol_df['red_champs1'],lol_df['red_champs2'],lol_df['red_champs3'],\n",
    "            lol_df['red_champs4']),axis=None)\n",
    "\n",
    "unique, counts= np.unique(champ_sum, return_counts=True)\n",
    "print(len(unique))\n",
    "plt.plot(np.log10(counts),'.')\n",
    "plt.xlabel('champion(arb)')\n",
    "plt.ylabel('log10(count)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define preprocess functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T22:16:02.294346Z",
     "start_time": "2019-11-06T22:16:02.287929Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "def _int64_list_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n",
    "def _bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "def _float_feature(value):\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T00:40:07.370705Z",
     "start_time": "2019-06-17T00:40:07.356816Z"
    },
    "code_folding": [
     3
    ]
   },
   "outputs": [],
   "source": [
    "#target_name to name tfrecords file and the target_df column to call\n",
    "#for now don't keep all possible targets in target_df\n",
    "#target_df selection is made with the preprocess_target function call\n",
    "def convert_to_tfrecords(filename, examples, target_df,target_name):\n",
    "    # open the TFRecords file\n",
    "    writer = tf.python_io.TFRecordWriter(filename)\n",
    "    \n",
    "    blue_hero_array = np.array(examples['blue_champs'])\n",
    "    red_hero_array = np.array(examples['red_champs'])\n",
    "    target_array = np.array(target_df[target_name])\n",
    "    \n",
    "    for i in range(len(blue_hero_array[:])):\n",
    "        # print how many games are saved every 10000 games\n",
    "        if not i % 10000:\n",
    "            print('Train data: %d/%d' % (i, len(examples)))\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "        # Load the hero_array\n",
    "        blue_champs = blue_hero_array[:][i].tostring()\n",
    "        red_champs = red_hero_array[:][i].tostring()\n",
    "        target = target_array[i]\n",
    "\n",
    "        # Create a feature\n",
    "        if target_name=='blue_win':\n",
    "            feature = {'blue_champs': _bytes_feature(tf.compat.as_bytes(blue_champs)),\n",
    "                   'red_champs': _bytes_feature(tf.compat.as_bytes(red_champs)),\n",
    "                   'targets': _int64_feature(target)}\n",
    "        else:\n",
    "            feature = {'blue_champs': _bytes_feature(tf.compat.as_bytes(blue_champs)),\n",
    "                   'red_champs': _bytes_feature(tf.compat.as_bytes(red_champs)),\n",
    "                   'targets': _float_feature(target)}\n",
    "        # Create an example protocol buffer\n",
    "        example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "    \n",
    "        # Serialize to string and write on the file\n",
    "        writer.write(example.SerializeToString())\n",
    "    \n",
    "    writer.close()\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T23:33:15.102638Z",
     "start_time": "2019-11-08T23:33:15.086180Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#target_name to name tfrecords file and the target_df column to call\n",
    "#for now don't keep all possible targets in target_df\n",
    "#target_df selection is made with the preprocess_target function call\n",
    "def convert_to_tfrecords_dota2_compat(filename, examples, target_df,target_name):\n",
    "    # open the TFRecords file\n",
    "    options = tf.io.TFRecordOptions('GZIP')\n",
    "    writer = tf.io.TFRecordWriter(filename,options=options)\n",
    "    \n",
    "    blue_hero_array = np.array(examples['blue_champs'])\n",
    "    red_hero_array = np.array(examples['red_champs'])\n",
    "    skill_level_array = np.array(examples['skill_level'])\n",
    "    target_array = np.array(target_df[target_name])\n",
    "\n",
    "    for i in range(len(blue_hero_array[:])):\n",
    "        # print how many games are saved every 10000 games\n",
    "        if not i % 10000:\n",
    "            print('Train data: %d/%d' % (i, len(examples)))\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "        # Load the hero_array\n",
    "        blue_champs = blue_hero_array[:][i]\n",
    "        red_champs = red_hero_array[:][i]\n",
    "        \n",
    "        blue_champs_index=[]\n",
    "        red_champs_index=[]\n",
    "        pass_outer=False\n",
    "        counter=0\n",
    "        for red_champ,blue_champ in zip(red_champs,blue_champs):\n",
    "            #add heroes to the heroes by index list for this game\n",
    "            try:\n",
    "                red_champs_index.append(champ_vocab.index(red_champ))\n",
    "                blue_champs_index.append(champ_vocab.index(blue_champ))\n",
    "            #if the hero isnt in the vocab then break and pass so \n",
    "            #  the example isnt used for training\n",
    "            except ValueError:\n",
    "                counter+=1\n",
    "                pass_outer = True\n",
    "                break\n",
    "        if pass_outer:\n",
    "            pass_outer=False\n",
    "            continue\n",
    "            \n",
    "\n",
    "        skill_level = skill_level_array[i]\n",
    "        #convert skill_level to one_hot\n",
    "        skill_level = tf.keras.utils.to_categorical(skill_level,\n",
    "                                                    num_classes=2,\n",
    "                                                    dtype='int64')\n",
    "\n",
    "        target = target_array[i]\n",
    "        \n",
    "        # Create a feature\n",
    "        if target_name=='blue_win':\n",
    "            feature = {'radiant_heroes': _int64_list_feature(blue_champs_index),\n",
    "                   'dire_heroes': _int64_list_feature(red_champs_index),\n",
    "                   'skill_level': _int64_list_feature(skill_level),\n",
    "                   'targets': _int64_feature(target)}\n",
    "        else:\n",
    "            feature = {'blue_champs': _int64_list_feature(blue_champs_index),\n",
    "                   'red_champs': _int64_list_feature(red_champs_index),\n",
    "                   'skill_level': _int64_list_feature(skill_level),\n",
    "                   'targets': _float_feature(target)}\n",
    "        \n",
    "        # Create an example protocol buffer\n",
    "        example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "    \n",
    "        # Serialize to string and write on the file\n",
    "        writer.write(example.SerializeToString())\n",
    "    \n",
    "    writer.close()\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T22:55:01.586110Z",
     "start_time": "2019-11-08T22:55:01.561905Z"
    },
    "code_folding": [
     3
    ]
   },
   "outputs": [],
   "source": [
    "#target_name to name tfrecords file and the target_df column to call\n",
    "#for now don't keep all possible targets in target_df\n",
    "#target_df selection is made with the preprocess_target function call\n",
    "def convert_to_tfrecords_dual(filename, examples, target_df):\n",
    "    # open the TFRecords file\n",
    "    writer = tf.python_io.TFRecordWriter(filename)\n",
    "    \n",
    "    blue_hero_array = np.array(examples['blue_champs'])\n",
    "    red_hero_array = np.array(examples['red_champs'])\n",
    "    win_array = np.array(target_df['blue_win'])\n",
    "    gold_diff_array = np.array(target_df['gold_diff'])\n",
    "    \n",
    "    for i in range(len(blue_hero_array[:])):\n",
    "        # print how many games are saved every 10000 games\n",
    "        if not i % 10000:\n",
    "            print('Train data: %d/%d' % (i, len(examples)))\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "        # Load the hero_array\n",
    "        blue_champs = blue_hero_array[:][i].tostring()\n",
    "        red_champs = red_hero_array[:][i].tostring()\n",
    "        blue_win = win_array[i]\n",
    "        gold_diff = gold_diff_array[i]\n",
    "        \n",
    "        # Create a feature\n",
    "        feature = {'blue_champs': _bytes_feature(tf.compat.as_bytes(blue_champs)),\n",
    "                   'red_champs': _bytes_feature(tf.compat.as_bytes(red_champs)),\n",
    "                   'blue_win': _int64_feature(blue_win),\n",
    "                   'gold_diff': _float_feature(gold_diff)}\n",
    "\n",
    "        # Create an example protocol buffer\n",
    "        example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "    \n",
    "        # Serialize to string and write on the file\n",
    "        writer.write(example.SerializeToString())\n",
    "    \n",
    "    writer.close()\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T23:32:05.689175Z",
     "start_time": "2019-11-08T23:32:05.673909Z"
    },
    "code_folding": [
     3
    ]
   },
   "outputs": [],
   "source": [
    "#target_name to name tfrecords file and the target_df column to call\n",
    "#for now don't keep all possible targets in target_df\n",
    "#target_df selection is made with the preprocess_target function call\n",
    "def convert_to_tfrecords_dual_dota2_compat(filename, examples, target_df):\n",
    "    # open the TFRecords file\n",
    "    options = tf.io.TFRecordOptions('GZIP')\n",
    "    writer = tf.io.TFRecordWriter(filename,options=options)\n",
    "    \n",
    "    blue_hero_array = np.array(examples['blue_champs'])\n",
    "    red_hero_array = np.array(examples['red_champs'])\n",
    "    skill_level_array = np.array(examples['skill_level'])\n",
    "\n",
    "    win_array = np.array(target_df['blue_win'])\n",
    "    gold_diff_array = np.array(target_df['gold_diff'])\n",
    "    \n",
    "    for i in range(len(blue_hero_array[:])):\n",
    "        # print how many games are saved every 10000 games\n",
    "        if not i % 10000:\n",
    "            print('Train data: %d/%d' % (i, len(examples)))\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "        # Load the hero_array\n",
    "        blue_champs = blue_hero_array[:][i]\n",
    "        red_champs = red_hero_array[:][i]\n",
    "        blue_win = win_array[i]\n",
    "        gold_diff = gold_diff_array[i]\n",
    "        skill_level = skill_level_array[i]\n",
    "\n",
    "        #convert skill_level to one_hot\n",
    "        skill_level = tf.keras.utils.to_categorical(skill_level,\n",
    "                                                    num_classes=2,\n",
    "                                                    dtype='int64')        \n",
    "        blue_champs_index=[]\n",
    "        red_champs_index=[]\n",
    "        pass_outer=False\n",
    "        counter=0\n",
    "        for red_champ,blue_champ in zip(red_champs,blue_champs):\n",
    "            #add heroes to the heroes by index list for this game\n",
    "            try:\n",
    "                red_champs_index.append(champ_vocab.index(red_champ))\n",
    "                blue_champs_index.append(champ_vocab.index(blue_champ))\n",
    "            #if the hero isnt in the vocab then break and pass so \n",
    "            #  the example isnt used for training\n",
    "            except ValueError:\n",
    "                counter+=1\n",
    "                pass_outer = True\n",
    "                break\n",
    "        if pass_outer:\n",
    "            pass_outer=False\n",
    "            continue\n",
    "\n",
    "        # Create a feature\n",
    "        feature = {'radiant_heroes': _int64_list_feature(blue_champs_index),\n",
    "                   'dire_heroes': _int64_list_feature(red_champs_index),\n",
    "                   'skill_level': _int64_list_feature(skill_level),\n",
    "                   'radiant_win': _int64_feature(blue_win),\n",
    "                   'gold_diff': _float_feature(gold_diff)}\n",
    "\n",
    "        # Create an example protocol buffer\n",
    "        example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "    \n",
    "        # Serialize to string and write on the file\n",
    "        writer.write(example.SerializeToString())\n",
    "    \n",
    "    writer.close()\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T23:32:25.671952Z",
     "start_time": "2019-11-08T23:32:25.654431Z"
    },
    "code_folding": [
     3
    ]
   },
   "outputs": [],
   "source": [
    "#target_name to name tfrecords file and the target_df column to call\n",
    "#for now don't keep all possible targets in target_df\n",
    "#target_df selection is made with the preprocess_target function call\n",
    "def convert_to_tfrecords_triple_dota2_compat(filename, examples, target_df):\n",
    "    # open the TFRecords file\n",
    "    options = tf.io.TFRecordOptions('GZIP')\n",
    "    writer = tf.io.TFRecordWriter(filename,options=options)\n",
    "    \n",
    "    blue_hero_array = np.array(examples['blue_champs'])\n",
    "    red_hero_array = np.array(examples['red_champs'])\n",
    "    skill_array = np.array(examples['skill_level'])\n",
    "    win_array = np.array(target_df['blue_win'])\n",
    "    gold_diff_array = np.array(target_df['gold_diff'])\n",
    "    total_gold_array = np.array(target_df['total_gold'])\n",
    "    \n",
    "    for i in range(len(blue_hero_array[:])):\n",
    "        # print how many games are saved every 10000 games\n",
    "        if not i % 10000:\n",
    "            print('Train data: %d/%d' % (i, len(examples)))\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "        # Load the hero_array\n",
    "        blue_champs = blue_hero_array[:][i]\n",
    "        red_champs = red_hero_array[:][i]\n",
    "        blue_win = win_array[i]\n",
    "        gold_diff = gold_diff_array[i]\n",
    "        total_gold = total_gold_array[i]\n",
    "        \n",
    "        skill_level = skill_array[i]\n",
    "        #convert skill_level to one_hot\n",
    "        \n",
    "        skill_level = tf.keras.utils.to_categorical(skill_level,\n",
    "                                                    num_classes=2,\n",
    "                                                    dtype='int64')        \n",
    "        counter=0\n",
    "        blue_champs_index=[]\n",
    "        red_champs_index=[]\n",
    "        pass_outer=False\n",
    "        for red_champ,blue_champ in zip(red_champs,blue_champs):\n",
    "            #add heroes to the heroes by index list for this game\n",
    "            try:\n",
    "                red_champs_index.append(champ_vocab.index(red_champ))\n",
    "                blue_champs_index.append(champ_vocab.index(blue_champ))\n",
    "            #if the hero isnt in the vocab then break and pass so \n",
    "            #  the example isnt used for training\n",
    "            except ValueError:\n",
    "                counter+=1\n",
    "                pass_outer = True\n",
    "                break\n",
    "        if pass_outer:\n",
    "            pass_outer=False\n",
    "            continue\n",
    "\n",
    "        # Create a feature\n",
    "        feature = {'radiant_heroes': _int64_list_feature(blue_champs_index),\n",
    "                   'dire_heroes': _int64_list_feature(red_champs_index),\n",
    "                   'skill_level': _int64_list_feature(skill_level),\n",
    "                   'radiant_win': _int64_feature(blue_win),\n",
    "                   'gold_diff': _float_feature(gold_diff),\n",
    "                   'total_gold': _float_feature(total_gold)}\n",
    "\n",
    "        # Create an example protocol buffer\n",
    "        example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "    \n",
    "        # Serialize to string and write on the file\n",
    "        writer.write(example.SerializeToString())\n",
    "    print('Out of vocab:',counter)\n",
    "    writer.close()\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-09T17:42:20.542739Z",
     "start_time": "2019-11-09T17:42:20.500381Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#target_name to name tfrecords file and the target_df column to call\n",
    "#for now don't keep all possible targets in target_df\n",
    "#target_df selection is made with the preprocess_target function call\n",
    "def convert_to_tfrecords_penta_dota2_compat(filename, examples, target_df):\n",
    "    # open the TFRecords file\n",
    "    options = tf.io.TFRecordOptions('GZIP')\n",
    "    writer = tf.io.TFRecordWriter(filename,options=options)\n",
    "    \n",
    "    blue_hero_array = np.array(examples['blue_champs'])\n",
    "    red_hero_array = np.array(examples['red_champs'])\n",
    "    skill_array = np.array(examples['skill_level'])\n",
    "    win_array = np.array(target_df['blue_win'])\n",
    "    gold_diff_array = np.array(target_df['gold_diff'])\n",
    "    total_gold_array = np.array(target_df['total_gold'])\n",
    "    towkill_diff_array = np.array(target_df['towkill_diff'])\n",
    "    towkill_total_array = np.array(target_df['towkill_total'])\n",
    "    \n",
    "    for i in range(len(blue_hero_array[:])):\n",
    "        # print how many games are saved every 10000 games\n",
    "        if not i % 10000:\n",
    "            print('Train data: %d/%d' % (i, len(examples)))\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "        # Load the hero_array\n",
    "        blue_champs = blue_hero_array[:][i]\n",
    "        red_champs = red_hero_array[:][i]\n",
    "        blue_win = win_array[i]\n",
    "        gold_diff = gold_diff_array[i]\n",
    "        total_gold = total_gold_array[i]\n",
    "        towkill_diff = towkill_diff_array[i]\n",
    "        towkill_total = towkill_total_array[i]\n",
    "        \n",
    "        skill_level = skill_array[i]\n",
    "        #convert skill_level to one_hot\n",
    "        skill_level = tf.keras.utils.to_categorical(skill_level,\n",
    "                                                    num_classes=2,\n",
    "                                                    dtype='int64')        \n",
    "        blue_champs_index=[]\n",
    "        red_champs_index=[]\n",
    "        pass_outer=False\n",
    "        counter=0\n",
    "        for j in range(5):\n",
    "            #add heroes to the heroes by index list for this game\n",
    "            try:\n",
    "                red_champs_index.append(champ_vocab.index(red_champs[j]))\n",
    "                blue_champs_index.append(champ_vocab.index(blue_champs[j]))\n",
    "            #if the hero isnt in the vocab then break and pass so \n",
    "            #  the example isnt used for training\n",
    "            except ValueError:\n",
    "                counter+=1\n",
    "                pass_outer = True\n",
    "                break\n",
    "        if pass_outer:\n",
    "            pass_outer=False\n",
    "            continue\n",
    "\n",
    "        # Create a feature\n",
    "        feature = {'radiant_heroes': _int64_list_feature(blue_champs_index),\n",
    "                   'dire_heroes': _int64_list_feature(red_champs_index),\n",
    "                   'skill_level': _int64_list_feature(skill_level),\n",
    "                   'radiant_win': _int64_feature(blue_win),\n",
    "                   'gold_diff': _float_feature(gold_diff),\n",
    "                   'total_gold': _float_feature(total_gold),\n",
    "                   'tower_damage_diff': _float_feature(towkill_diff),\n",
    "                   'total_tower_damage': _float_feature(towkill_total)}\n",
    "\n",
    "        # Create an example protocol buffer\n",
    "        example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "    \n",
    "        # Serialize to string and write on the file\n",
    "        writer.write(example.SerializeToString())\n",
    "    \n",
    "    writer.close()\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-09T17:38:00.780812Z",
     "start_time": "2019-11-09T17:38:00.620177Z"
    },
    "code_folding": [
     3,
     5,
     27,
     39,
     51,
     66,
     83,
     105
    ]
   },
   "outputs": [],
   "source": [
    "def z_score(column):\n",
    "    return (column-column.mean())/column.std()\n",
    "\n",
    "def preprocess_features(lol_df):\n",
    "    \"\"\"Take lol_df and create a dataframe containing only the features for our model\n",
    "            Args: \n",
    "                lol_df: Dataframe containing lol training and test data\n",
    "            returns: \n",
    "                processed_df: pandas DataFrame containing only feature columns\n",
    "    \"\"\"\n",
    "    \n",
    "    #Use arrays of champs for each team as features rather than each hero\n",
    "    #individually to help model fit?\n",
    "    #This is an attempt to make the model more similar to the movie review\n",
    "    #text analysis example in the Google ML Crash Course\n",
    "    processed_df = pd.DataFrame()\n",
    "    \n",
    "    processed_df['blue_champs'] = list(np.array(lol_df.loc[:,['blue_champs0',\n",
    "                                                'blue_champs1','blue_champs2',\n",
    "                                                'blue_champs3','blue_champs4']]).astype(int))\n",
    "    processed_df['red_champs'] = list(np.array(lol_df.loc[:,['red_champs0',\n",
    "                                    'red_champs1','red_champs2',\n",
    "                                    'red_champs3','red_champs4']]).astype(int))\n",
    "    processed_df['skill_level'] = list(np.array(lol_df['skill_level']).astype(int))\n",
    "    \n",
    "    return processed_df\n",
    "    \n",
    "def preprocess_targets_win(lol_df):\n",
    "    \"\"\"Take lol_df and create a dataframe containing only the targets for our model. (blue_win here)\n",
    "            Args: \n",
    "                lol_df: Dataframe containing lol training and test data\n",
    "            returns: \n",
    "                target_df: pandas DataFrame containing only the target column\n",
    "    \"\"\"\n",
    "    target_df = pd.DataFrame()\n",
    "    target_df['blue_win'] = lol_df['blue_win']\n",
    "    \n",
    "    return target_df\n",
    "\n",
    "def preprocess_targets_gold(lol_df):\n",
    "    \"\"\"Take lol_df and create a dataframe containing only the targets for our model \n",
    "        (normalized gold difference in this case)\n",
    "            Args: \n",
    "                lol_df: Dataframe containing lol training and test data\n",
    "            returns: \n",
    "                target_df: pandas DataFrame containing only the target column (gold_diff)\n",
    "    \"\"\"\n",
    "    target_df = pd.DataFrame()\n",
    "    target_df['gold_diff'] = zscore(lol_df['blue_gold']-lol_df['red_gold'])\n",
    "    return target_df\n",
    "\n",
    "def preprocess_targets_dual_gold_win(lol_df):\n",
    "    \"\"\"Take lol_df and create a dataframe containing only the targets for our model \n",
    "        (normalized gold difference in this case)\n",
    "            Args: \n",
    "                lol_df: Dataframe containing lol training and test data\n",
    "            returns: \n",
    "                target_df: pandas DataFrame containing only the target column (gold_diff)\n",
    "    \"\"\"\n",
    "    target_df = pd.DataFrame()\n",
    "    target_df['blue_win'] = lol_df['blue_win']\n",
    "    target_df['gold_diff'] = lol_df['blue_gold']-lol_df['red_gold']\n",
    "    target_df['gold_diff'] = z_score(target_df['gold_diff'])\n",
    "    \n",
    "    return target_df\n",
    "\n",
    "def preprocess_targets_triple_gold_win(lol_df):\n",
    "    \"\"\"Take lol_df and create a dataframe containing only the targets for our model \n",
    "        (normalized gold difference in this case)\n",
    "            Args: \n",
    "                lol_df: Dataframe containing lol training and test data\n",
    "            returns: \n",
    "                target_df: pandas DataFrame containing only the target column (gold_diff)\n",
    "    \"\"\"\n",
    "    target_df = pd.DataFrame()\n",
    "    target_df['blue_win'] = lol_df['blue_win']\n",
    "    target_df['gold_diff'] = lol_df['blue_gold']-lol_df['red_gold']\n",
    "    target_df['gold_diff'] = z_score(target_df['gold_diff'])\n",
    "    target_df['total_gold'] = lol_df['blue_gold']+lol_df['red_gold']\n",
    "    target_df['total_gold'] = z_score(target_df['total_gold'])\n",
    "\n",
    "    return target_df\n",
    "\n",
    "def preprocess_targets_penta_gold_win_tow(lol_df):\n",
    "    \"\"\"Take lol_df and create a dataframe containing only the targets for our model \n",
    "        (normalized gold difference in this case)\n",
    "            Args: \n",
    "                lol_df: Dataframe containing lol training and test data\n",
    "            returns: \n",
    "                target_df: pandas DataFrame containing only the target column (gold_diff)\n",
    "    \"\"\"\n",
    "    target_df = pd.DataFrame()\n",
    "    target_df['blue_win'] = lol_df['blue_win']\n",
    "    target_df['gold_diff'] = lol_df['blue_gold']-lol_df['red_gold']\n",
    "    target_df['gold_diff'] = z_score(target_df['gold_diff'])\n",
    "    target_df['total_gold'] = lol_df['blue_gold']+lol_df['red_gold']\n",
    "    target_df['total_gold'] = z_score(target_df['total_gold'])\n",
    "    target_df['towkill_diff'] = lol_df['blue_tower_kills']-lol_df['red_tower_kills']\n",
    "    target_df['towkill_diff'] = z_score(target_df['towkill_diff'].astype('float32'))\n",
    "    target_df['towkill_total'] = lol_df['blue_tower_kills']-lol_df['red_tower_kills']\n",
    "    target_df['towkill_total'] = z_score(target_df['towkill_total'].astype('float32'))\n",
    "\n",
    "    return target_df\n",
    "\n",
    "#this can be easily modified for baron, dragon, or inhib kills\n",
    "def preprocess_targets_towerkills(lol_df):\n",
    "    \"\"\"Take lol_df and create a dataframe containing only the targets for our model \n",
    "        (normalized tower_kill difference in this case)\n",
    "            Args: \n",
    "                lol_df: Dataframe containing lol training and test data\n",
    "            returns: \n",
    "                target_df: pandas DataFrame containing only the target column (tower_kills)\n",
    "    \"\"\"\n",
    "\n",
    "    target_df = pd.DataFrame()\n",
    "    target_df['towkill_diff'] = z_score(lol_df['blue_tower_kills']\\\n",
    "                                        -lol_df['red_tower_kills'])\n",
    "    return target_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize data for each set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T22:36:19.188530Z",
     "start_time": "2019-11-06T22:36:19.161913Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_len' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-138ce5d2abe8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplotting_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlol_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplotting_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrain_len\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplotting_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_len\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrain_len\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mtest_len\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplotting_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_len\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mtest_len\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_len' is not defined"
     ]
    }
   ],
   "source": [
    "plotting_df = lol_df\n",
    "\n",
    "display.display(plotting_df.iloc[:train_len,:].describe())\n",
    "display.display(plotting_df.iloc[train_len:train_len+test_len,:].describe())\n",
    "display.display(plotting_df.iloc[train_len+test_len:,:].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-16T04:37:27.003987Z",
     "start_time": "2019-04-15T05:08:40.285Z"
    },
    "heading_collapsed": true
   },
   "source": [
    "### Export win tfrecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-31T02:06:01.720311Z",
     "start_time": "2019-05-31T02:05:18.309396Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: 0/309173\n",
      "Train data: 10000/309173\n",
      "Train data: 20000/309173\n",
      "Train data: 30000/309173\n",
      "Train data: 40000/309173\n",
      "Train data: 50000/309173\n",
      "Train data: 60000/309173\n",
      "Train data: 70000/309173\n",
      "Train data: 80000/309173\n",
      "Train data: 90000/309173\n",
      "Train data: 100000/309173\n",
      "Train data: 110000/309173\n",
      "Train data: 120000/309173\n",
      "Train data: 130000/309173\n",
      "Train data: 140000/309173\n",
      "Train data: 150000/309173\n",
      "Train data: 160000/309173\n",
      "Train data: 170000/309173\n",
      "Train data: 180000/309173\n",
      "Train data: 190000/309173\n",
      "Train data: 200000/309173\n",
      "Train data: 210000/309173\n",
      "Train data: 220000/309173\n",
      "Train data: 230000/309173\n",
      "Train data: 240000/309173\n",
      "Train data: 250000/309173\n",
      "Train data: 260000/309173\n",
      "Train data: 270000/309173\n",
      "Train data: 280000/309173\n",
      "Train data: 290000/309173\n",
      "Train data: 300000/309173\n",
      "Train data: 0/88336\n",
      "Train data: 10000/88336\n",
      "Train data: 20000/88336\n",
      "Train data: 30000/88336\n",
      "Train data: 40000/88336\n",
      "Train data: 50000/88336\n",
      "Train data: 60000/88336\n",
      "Train data: 70000/88336\n",
      "Train data: 80000/88336\n",
      "Train data: 0/44168\n",
      "Train data: 10000/44168\n",
      "Train data: 20000/44168\n",
      "Train data: 30000/44168\n",
      "Train data: 40000/44168\n"
     ]
    }
   ],
   "source": [
    "tier = 'mix_tier'\n",
    "training_frac = 0.7\n",
    "train_len = int(len(lol_df) * training_frac)\n",
    "test_len = int((len(lol_df) - train_len)/1.5)\n",
    "validation_len = len(lol_df) - train_len - test_len\n",
    "\n",
    "target_name='blue_win'\n",
    "train_features = preprocess_features(lol_df.iloc[:train_len,:])\n",
    "test_features = preprocess_features(lol_df.iloc[train_len:train_len+test_len,:])\n",
    "validation_features = preprocess_features(lol_df.iloc[train_len+test_len:,:])\n",
    "\n",
    "if target_name=='blue_win':\n",
    "    train_targets = preprocess_targets_win(lol_df.iloc[:train_len,:])\n",
    "    test_targets = preprocess_targets_win(lol_df.iloc[train_len:train_len+test_len,:])\n",
    "    validation_targets = preprocess_targets_win(lol_df.iloc[train_len+test_len:,:])\n",
    "else:\n",
    "    train_targets = preprocess_targets_gold(lol_df.iloc[:train_len,:])\n",
    "    test_targets = preprocess_targets_gold(lol_df.iloc[train_len:train_len+test_len,:])\n",
    "    validation_targets = preprocess_targets_gold(lol_df.iloc[train_len+test_len:,:])\n",
    "\n",
    "\n",
    "\n",
    "convert_to_tfrecords(os.path.join('LOL_data',tier,'lol_training_data', \n",
    "                     target_name+'_lol_training_data.tfrecords'),\n",
    "                     train_features,\n",
    "                     train_targets,\n",
    "                     target_name=target_name)\n",
    "\n",
    "convert_to_tfrecords(os.path.join('LOL_data',tier,'lol_test_data', \n",
    "                     target_name+'_lol_test_data.tfrecords'),\n",
    "                     test_features,\n",
    "                     test_targets,\n",
    "                     target_name=target_name)\n",
    "\n",
    "convert_to_tfrecords(os.path.join('LOL_data',tier,'lol_validation_data',\n",
    "                     target_name+'_lol_validation_data.tfrecords'),\n",
    "                     validation_features,\n",
    "                     validation_targets,\n",
    "                     target_name=target_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export win dota2 compat tfrecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T23:35:31.315662Z",
     "start_time": "2019-11-08T23:33:18.085360Z"
    },
    "code_folding": [
     11,
     15,
     20,
     26,
     32
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: 0/309173\n",
      "Train data: 10000/309173\n",
      "Train data: 20000/309173\n",
      "Train data: 30000/309173\n",
      "Train data: 40000/309173\n",
      "Train data: 50000/309173\n",
      "Train data: 60000/309173\n",
      "Train data: 70000/309173\n",
      "Train data: 80000/309173\n",
      "Train data: 90000/309173\n",
      "Train data: 100000/309173\n",
      "Train data: 110000/309173\n",
      "Train data: 120000/309173\n",
      "Train data: 130000/309173\n",
      "Train data: 140000/309173\n",
      "Train data: 150000/309173\n",
      "Train data: 160000/309173\n",
      "Train data: 170000/309173\n",
      "Train data: 180000/309173\n",
      "Train data: 190000/309173\n",
      "Train data: 200000/309173\n",
      "Train data: 210000/309173\n",
      "Train data: 220000/309173\n",
      "Train data: 230000/309173\n",
      "Train data: 240000/309173\n",
      "Train data: 250000/309173\n",
      "Train data: 260000/309173\n",
      "Train data: 270000/309173\n",
      "Train data: 280000/309173\n",
      "Train data: 290000/309173\n",
      "Train data: 300000/309173\n",
      "Train data: 0/88336\n",
      "Train data: 10000/88336\n",
      "Train data: 20000/88336\n",
      "Train data: 30000/88336\n",
      "Train data: 40000/88336\n",
      "Train data: 50000/88336\n",
      "Train data: 60000/88336\n",
      "Train data: 70000/88336\n",
      "Train data: 80000/88336\n",
      "Train data: 0/44168\n",
      "Train data: 10000/44168\n",
      "Train data: 20000/44168\n",
      "Train data: 30000/44168\n",
      "Train data: 40000/44168\n"
     ]
    }
   ],
   "source": [
    "tier = 'mix_tier'\n",
    "training_frac = 0.7\n",
    "train_len = int(len(lol_df) * training_frac)\n",
    "test_len = int((len(lol_df) - train_len)/1.5)\n",
    "validation_len = len(lol_df) - train_len - test_len\n",
    "\n",
    "target_name='blue_win'\n",
    "train_features = preprocess_features(lol_df.iloc[:train_len,:])\n",
    "test_features = preprocess_features(lol_df.iloc[train_len:train_len+test_len,:])\n",
    "validation_features = preprocess_features(lol_df.iloc[train_len+test_len:,:])\n",
    "\n",
    "if target_name=='blue_win':\n",
    "    train_targets = preprocess_targets_win(lol_df.iloc[:train_len,:])\n",
    "    test_targets = preprocess_targets_win(lol_df.iloc[train_len:train_len+test_len,:])\n",
    "    validation_targets = preprocess_targets_win(lol_df.iloc[train_len+test_len:,:])\n",
    "else:\n",
    "    train_targets = preprocess_targets_gold(lol_df.iloc[:train_len,:])\n",
    "    test_targets = preprocess_targets_gold(lol_df.iloc[train_len:train_len+test_len,:])\n",
    "    validation_targets = preprocess_targets_gold(lol_df.iloc[train_len+test_len:,:])\n",
    "\n",
    "convert_to_tfrecords_dota2_compat(os.path.join('LOL_data',tier,'lol_training_data', \n",
    "                     target_name+'_dota2_compat_lol_training_data.tfrecords'),\n",
    "                     train_features,\n",
    "                     train_targets,\n",
    "                     target_name=target_name)\n",
    "\n",
    "convert_to_tfrecords_dota2_compat(os.path.join('LOL_data',tier,'lol_test_data', \n",
    "                     target_name+'_dota2_compat_lol_test_data.tfrecords'),\n",
    "                     test_features,\n",
    "                     test_targets,\n",
    "                     target_name=target_name)\n",
    "\n",
    "convert_to_tfrecords_dota2_compat(os.path.join('LOL_data',tier,'lol_validation_data',\n",
    "                     target_name+'_dota2_compat_lol_validation_data.tfrecords'),\n",
    "                     validation_features,\n",
    "                     validation_targets,\n",
    "                     target_name=target_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Export gold tfrecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T00:30:51.470487Z",
     "start_time": "2019-06-17T00:30:08.080242Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: 0/309173\n",
      "Train data: 10000/309173\n",
      "Train data: 20000/309173\n",
      "Train data: 30000/309173\n",
      "Train data: 40000/309173\n",
      "Train data: 50000/309173\n",
      "Train data: 60000/309173\n",
      "Train data: 70000/309173\n",
      "Train data: 80000/309173\n",
      "Train data: 90000/309173\n",
      "Train data: 100000/309173\n",
      "Train data: 110000/309173\n",
      "Train data: 120000/309173\n",
      "Train data: 130000/309173\n",
      "Train data: 140000/309173\n",
      "Train data: 150000/309173\n",
      "Train data: 160000/309173\n",
      "Train data: 170000/309173\n",
      "Train data: 180000/309173\n",
      "Train data: 190000/309173\n",
      "Train data: 200000/309173\n",
      "Train data: 210000/309173\n",
      "Train data: 220000/309173\n",
      "Train data: 230000/309173\n",
      "Train data: 240000/309173\n",
      "Train data: 250000/309173\n",
      "Train data: 260000/309173\n",
      "Train data: 270000/309173\n",
      "Train data: 280000/309173\n",
      "Train data: 290000/309173\n",
      "Train data: 300000/309173\n",
      "Train data: 0/88336\n",
      "Train data: 10000/88336\n",
      "Train data: 20000/88336\n",
      "Train data: 30000/88336\n",
      "Train data: 40000/88336\n",
      "Train data: 50000/88336\n",
      "Train data: 60000/88336\n",
      "Train data: 70000/88336\n",
      "Train data: 80000/88336\n",
      "Train data: 0/44168\n",
      "Train data: 10000/44168\n",
      "Train data: 20000/44168\n",
      "Train data: 30000/44168\n",
      "Train data: 40000/44168\n"
     ]
    }
   ],
   "source": [
    "tier = 'mix_tier'\n",
    "training_frac = 0.7\n",
    "train_len = int(len(lol_df) * training_frac)\n",
    "test_len = int((len(lol_df) - train_len)/1.5)\n",
    "validation_len = len(lol_df) - train_len - test_len\n",
    "\n",
    "target_name='gold_diff'\n",
    "train_features = preprocess_features(lol_df.iloc[:train_len,:])\n",
    "test_features = preprocess_features(lol_df.iloc[train_len:train_len+test_len,:])\n",
    "validation_features = preprocess_features(lol_df.iloc[train_len+test_len:,:])\n",
    "\n",
    "if target_name=='blue_win':\n",
    "    train_targets = preprocess_targets_win(lol_df.iloc[:train_len,:])\n",
    "    test_targets = preprocess_targets_win(lol_df.iloc[train_len:train_len+test_len,:])\n",
    "    validation_targets = preprocess_targets_win(lol_df.iloc[train_len+test_len:,:])\n",
    "else:\n",
    "    train_targets = preprocess_targets_gold(lol_df.iloc[:train_len,:])\n",
    "    test_targets = preprocess_targets_gold(lol_df.iloc[train_len:train_len+test_len,:])\n",
    "    validation_targets = preprocess_targets_gold(lol_df.iloc[train_len+test_len:,:])\n",
    "\n",
    "convert_to_tfrecords(os.path.join('LOL_data',tier,'lol_training_data', \n",
    "                     target_name+'_lol_training_data.tfrecords'),\n",
    "                     train_features,\n",
    "                     train_targets,\n",
    "                     target_name=target_name)\n",
    "\n",
    "convert_to_tfrecords(os.path.join('LOL_data',tier,'lol_test_data', \n",
    "                     target_name+'_lol_test_data.tfrecords'),\n",
    "                     test_features,\n",
    "                     test_targets,\n",
    "                     target_name=target_name)\n",
    "\n",
    "convert_to_tfrecords(os.path.join('LOL_data',tier,'lol_validation_data',\n",
    "                     target_name+'_lol_validation_data.tfrecords'),\n",
    "                     validation_features,\n",
    "                     validation_targets,\n",
    "                     target_name=target_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Export dual gold_win tfrecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T04:48:57.332740Z",
     "start_time": "2019-11-08T04:48:50.848893Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'convert_to_tfrecords_dual' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-104-9c9a3deead3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mvalidation_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_targets_dual_gold_win\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlol_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_len\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mtest_len\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m convert_to_tfrecords_dual(os.path.join('LOL_data',tier,'lol_training_data', \n\u001b[0m\u001b[1;32m     18\u001b[0m                      target_name+'_lol_training_data.tfrecords'),\n\u001b[1;32m     19\u001b[0m                      \u001b[0mtrain_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'convert_to_tfrecords_dual' is not defined"
     ]
    }
   ],
   "source": [
    "tier = 'mix_tier'\n",
    "training_frac = 0.7\n",
    "train_len = int(len(lol_df) * training_frac)\n",
    "validation_len = int((len(lol_df) - train_len)/1.5)\n",
    "test_len = len(lol_df) - train_len - validation_len\n",
    "\n",
    "target_name='dual_gold_win'\n",
    "train_features = preprocess_features(lol_df.iloc[:train_len,:])\n",
    "test_features = preprocess_features(lol_df.iloc[train_len:train_len+test_len,:])\n",
    "validation_features = preprocess_features(lol_df.iloc[train_len+test_len:,:])\n",
    "\n",
    "\n",
    "train_targets = preprocess_targets_dual_gold_win(lol_df.iloc[:train_len,:])\n",
    "test_targets = preprocess_targets_dual_gold_win(lol_df.iloc[train_len:train_len+test_len,:])\n",
    "validation_targets = preprocess_targets_dual_gold_win(lol_df.iloc[train_len+test_len:,:])\n",
    "\n",
    "convert_to_tfrecords_dual(os.path.join('LOL_data',tier,'lol_training_data', \n",
    "                     target_name+'_lol_training_data.tfrecords'),\n",
    "                     train_features,\n",
    "                     train_targets)\n",
    "convert_to_tfrecords_dual(os.path.join('LOL_data',tier,'lol_test_data', \n",
    "                     target_name+'_lol_test_data.tfrecords'),\n",
    "                     test_features,\n",
    "                     test_targets)\n",
    "\n",
    "convert_to_tfrecords_dual(os.path.join('LOL_data',tier,'lol_validation_data',\n",
    "                     target_name+'_lol_validation_data.tfrecords'),\n",
    "                     validation_features,\n",
    "                     validation_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export dual model with dota compatibility for easy keras model reusing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T23:39:15.152173Z",
     "start_time": "2019-11-08T23:37:05.727130Z"
    },
    "code_folding": [
     15,
     19,
     24
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: 0/309173\n",
      "Train data: 10000/309173\n",
      "Train data: 20000/309173\n",
      "Train data: 30000/309173\n",
      "Train data: 40000/309173\n",
      "Train data: 50000/309173\n",
      "Train data: 60000/309173\n",
      "Train data: 70000/309173\n",
      "Train data: 80000/309173\n",
      "Train data: 90000/309173\n",
      "Train data: 100000/309173\n",
      "Train data: 110000/309173\n",
      "Train data: 120000/309173\n",
      "Train data: 130000/309173\n",
      "Train data: 140000/309173\n",
      "Train data: 150000/309173\n",
      "Train data: 160000/309173\n",
      "Train data: 170000/309173\n",
      "Train data: 180000/309173\n",
      "Train data: 190000/309173\n",
      "Train data: 200000/309173\n",
      "Train data: 210000/309173\n",
      "Train data: 220000/309173\n",
      "Train data: 230000/309173\n",
      "Train data: 240000/309173\n",
      "Train data: 250000/309173\n",
      "Train data: 260000/309173\n",
      "Train data: 270000/309173\n",
      "Train data: 280000/309173\n",
      "Train data: 290000/309173\n",
      "Train data: 300000/309173\n",
      "Train data: 0/44168\n",
      "Train data: 10000/44168\n",
      "Train data: 20000/44168\n",
      "Train data: 30000/44168\n",
      "Train data: 40000/44168\n",
      "Train data: 0/88336\n",
      "Train data: 10000/88336\n",
      "Train data: 20000/88336\n",
      "Train data: 30000/88336\n",
      "Train data: 40000/88336\n",
      "Train data: 50000/88336\n",
      "Train data: 60000/88336\n",
      "Train data: 70000/88336\n",
      "Train data: 80000/88336\n"
     ]
    }
   ],
   "source": [
    "tier = 'mix_tier'\n",
    "training_frac = 0.7\n",
    "train_len = int(len(lol_df) * training_frac)\n",
    "validation_len = int((len(lol_df) - train_len)/1.5)\n",
    "test_len = len(lol_df) - train_len - validation_len\n",
    "\n",
    "target_name='dual_gold_win_dota2_compat'\n",
    "train_features = preprocess_features(lol_df.iloc[:train_len,:])\n",
    "test_features = preprocess_features(lol_df.iloc[train_len:train_len+test_len,:])\n",
    "validation_features = preprocess_features(lol_df.iloc[train_len+test_len:,:])\n",
    "\n",
    "train_targets = preprocess_targets_dual_gold_win(lol_df.iloc[:train_len,:])\n",
    "test_targets = preprocess_targets_dual_gold_win(lol_df.iloc[train_len:train_len+test_len,:])\n",
    "validation_targets = preprocess_targets_dual_gold_win(lol_df.iloc[train_len+test_len:,:])\n",
    "\n",
    "convert_to_tfrecords_dual_dota2_compat(os.path.join('LOL_data',tier,'lol_training_data', \n",
    "                     target_name+'_lol_training_data.tfrecords'),\n",
    "                     train_features,\n",
    "                     train_targets)\n",
    "convert_to_tfrecords_dual_dota2_compat(os.path.join('LOL_data',tier,'lol_test_data', \n",
    "                     target_name+'_lol_test_data.tfrecords'),\n",
    "                     test_features,\n",
    "                     test_targets)\n",
    "\n",
    "convert_to_tfrecords_dual_dota2_compat(os.path.join('LOL_data',tier,'lol_validation_data',\n",
    "                     target_name+'_lol_validation_data.tfrecords'),\n",
    "                     validation_features,\n",
    "                     validation_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export triple win gold diff and total tfrecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T23:41:30.528706Z",
     "start_time": "2019-11-08T23:39:15.154699Z"
    },
    "code_folding": [
     16,
     20,
     25
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: 0/309173\n",
      "Train data: 10000/309173\n",
      "Train data: 20000/309173\n",
      "Train data: 30000/309173\n",
      "Train data: 40000/309173\n",
      "Train data: 50000/309173\n",
      "Train data: 60000/309173\n",
      "Train data: 70000/309173\n",
      "Train data: 80000/309173\n",
      "Train data: 90000/309173\n",
      "Train data: 100000/309173\n",
      "Train data: 110000/309173\n",
      "Train data: 120000/309173\n",
      "Train data: 130000/309173\n",
      "Train data: 140000/309173\n",
      "Train data: 150000/309173\n",
      "Train data: 160000/309173\n",
      "Train data: 170000/309173\n",
      "Train data: 180000/309173\n",
      "Train data: 190000/309173\n",
      "Train data: 200000/309173\n",
      "Train data: 210000/309173\n",
      "Train data: 220000/309173\n",
      "Train data: 230000/309173\n",
      "Train data: 240000/309173\n",
      "Train data: 250000/309173\n",
      "Train data: 260000/309173\n",
      "Train data: 270000/309173\n",
      "Train data: 280000/309173\n",
      "Train data: 290000/309173\n",
      "Train data: 300000/309173\n",
      "Out of vocab: 0\n",
      "Train data: 0/44168\n",
      "Train data: 10000/44168\n",
      "Train data: 20000/44168\n",
      "Train data: 30000/44168\n",
      "Train data: 40000/44168\n",
      "Out of vocab: 0\n",
      "Train data: 0/88336\n",
      "Train data: 10000/88336\n",
      "Train data: 20000/88336\n",
      "Train data: 30000/88336\n",
      "Train data: 40000/88336\n",
      "Train data: 50000/88336\n",
      "Train data: 60000/88336\n",
      "Train data: 70000/88336\n",
      "Train data: 80000/88336\n",
      "Out of vocab: 0\n"
     ]
    }
   ],
   "source": [
    "tier = 'mix_tier'\n",
    "training_frac = 0.7\n",
    "train_len = int(len(lol_df) * training_frac)\n",
    "validation_len = int((len(lol_df) - train_len)/1.5)\n",
    "test_len = len(lol_df) - train_len - validation_len\n",
    "\n",
    "target_name='triple_gold_win_dota2_compat'\n",
    "train_features = preprocess_features(lol_df.iloc[:train_len,:])\n",
    "test_features = preprocess_features(lol_df.iloc[train_len:train_len+test_len,:])\n",
    "validation_features = preprocess_features(lol_df.iloc[train_len+test_len:,:])\n",
    "\n",
    "\n",
    "train_targets = preprocess_targets_triple_gold_win(lol_df.iloc[:train_len,:])\n",
    "test_targets = preprocess_targets_triple_gold_win(lol_df.iloc[train_len:train_len+test_len,:])\n",
    "validation_targets = preprocess_targets_triple_gold_win(lol_df.iloc[train_len+test_len:,:])\n",
    "\n",
    "convert_to_tfrecords_triple_dota2_compat(os.path.join('LOL_data',tier,'lol_training_data', \n",
    "                     target_name+'_lol_training_data.tfrecords'),\n",
    "                     train_features,\n",
    "                     train_targets)\n",
    "convert_to_tfrecords_triple_dota2_compat(os.path.join('LOL_data',tier,'lol_test_data', \n",
    "                     target_name+'_lol_test_data.tfrecords'),\n",
    "                     test_features,\n",
    "                     test_targets)\n",
    "\n",
    "convert_to_tfrecords_triple_dota2_compat(os.path.join('LOL_data',tier,'lol_validation_data',\n",
    "                     target_name+'_lol_validation_data.tfrecords'),\n",
    "                     validation_features,\n",
    "                     validation_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export penta target tfrecord dota compat gold, tower (diff and total) and win"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-09T17:45:13.622650Z",
     "start_time": "2019-11-09T17:42:26.235244Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: 0/309173\n",
      "Train data: 10000/309173\n",
      "Train data: 20000/309173\n",
      "Train data: 30000/309173\n",
      "Train data: 40000/309173\n",
      "Train data: 50000/309173\n",
      "Train data: 60000/309173\n",
      "Train data: 70000/309173\n",
      "Train data: 80000/309173\n",
      "Train data: 90000/309173\n",
      "Train data: 100000/309173\n",
      "Train data: 110000/309173\n",
      "Train data: 120000/309173\n",
      "Train data: 130000/309173\n",
      "Train data: 140000/309173\n",
      "Train data: 150000/309173\n",
      "Train data: 160000/309173\n",
      "Train data: 170000/309173\n",
      "Train data: 180000/309173\n",
      "Train data: 190000/309173\n",
      "Train data: 200000/309173\n",
      "Train data: 210000/309173\n",
      "Train data: 220000/309173\n",
      "Train data: 230000/309173\n",
      "Train data: 240000/309173\n",
      "Train data: 250000/309173\n",
      "Train data: 260000/309173\n",
      "Train data: 270000/309173\n",
      "Train data: 280000/309173\n",
      "Train data: 290000/309173\n",
      "Train data: 300000/309173\n",
      "Train data: 0/44168\n",
      "Train data: 10000/44168\n",
      "Train data: 20000/44168\n",
      "Train data: 30000/44168\n",
      "Train data: 40000/44168\n",
      "Train data: 0/88336\n",
      "Train data: 10000/88336\n",
      "Train data: 20000/88336\n",
      "Train data: 30000/88336\n",
      "Train data: 40000/88336\n",
      "Train data: 50000/88336\n",
      "Train data: 60000/88336\n",
      "Train data: 70000/88336\n",
      "Train data: 80000/88336\n"
     ]
    }
   ],
   "source": [
    "tier = 'mix_tier'\n",
    "training_frac = 0.7\n",
    "train_len = int(len(lol_df) * training_frac)\n",
    "validation_len = int((len(lol_df) - train_len)/1.5)\n",
    "test_len = len(lol_df) - train_len - validation_len\n",
    "\n",
    "target_name='penta_gold_win_dota2_compat'\n",
    "train_features = preprocess_features(lol_df.iloc[:train_len,:])\n",
    "test_features = preprocess_features(lol_df.iloc[train_len:train_len+test_len,:])\n",
    "validation_features = preprocess_features(lol_df.iloc[train_len+test_len:,:])\n",
    "\n",
    "\n",
    "train_targets = preprocess_targets_penta_gold_win_tow(lol_df.iloc[:train_len,:])\n",
    "test_targets = preprocess_targets_penta_gold_win_tow(lol_df.iloc[train_len:train_len+test_len,:])\n",
    "validation_targets = preprocess_targets_penta_gold_win_tow(lol_df.iloc[train_len+test_len:,:])\n",
    "\n",
    "convert_to_tfrecords_penta_dota2_compat(os.path.join('LOL_data',tier,'lol_training_data', \n",
    "                     target_name+'_lol_training_data.tfrecords'),\n",
    "                     train_features,\n",
    "                     train_targets)\n",
    "\n",
    "convert_to_tfrecords_penta_dota2_compat(os.path.join('LOL_data',tier,'lol_test_data', \n",
    "                     target_name+'_lol_test_data.tfrecords'),\n",
    "                     test_features,\n",
    "                     test_targets)\n",
    "\n",
    "convert_to_tfrecords_penta_dota2_compat(os.path.join('LOL_data',tier,'lol_validation_data',\n",
    "                     target_name+'_lol_validation_data.tfrecords'),\n",
    "                     validation_features,\n",
    "                     validation_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "notify_time": "30",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
