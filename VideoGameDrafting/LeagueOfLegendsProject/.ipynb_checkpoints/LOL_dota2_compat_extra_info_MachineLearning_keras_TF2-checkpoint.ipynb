{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-14T21:20:49.674644Z",
     "start_time": "2020-03-14T21:20:44.415853Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import pylab as plt\n",
    "import numpy as np\n",
    "from steam import WebAPI\n",
    "from datetime import datetime\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "from IPython import display\n",
    "import requests\n",
    "import tensorflow.keras.backend as K\n",
    "from sklearn import decomposition\n",
    "\n",
    "#import logging\n",
    "#logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "\n",
    "#from tensorflow.python.framework.ops import disable_eager_execution\n",
    "#disable_eager_execution()\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-14T21:20:49.681651Z",
     "start_time": "2020-03-14T21:20:49.677199Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.set_style('ticks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-14T21:20:49.695451Z",
     "start_time": "2020-03-14T21:20:49.684598Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144\n"
     ]
    }
   ],
   "source": [
    "champfile=os.path.join('lol_data','version9.10.1_champion.json')\n",
    "with open(champfile,'r') as fin:\n",
    "    champdata=json.load(fin)\n",
    "champ_vocab=[]\n",
    "for name,data in champdata['data'].items():\n",
    "    champ_vocab.append(data['key'])\n",
    "hero_vocab = [int(i) for i in champ_vocab]\n",
    "print(len(hero_vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling using a TFRecord dataformat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build TFRecord input pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-14T21:50:35.253063Z",
     "start_time": "2020-03-14T21:50:35.234192Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def _parse_function_extra_info(example_proto):\n",
    "    \"\"\"Extracts features and labels.\n",
    "  \n",
    "    Args:\n",
    "        example_proto: tf.Example protocol (unsure what this is)    \n",
    "      Returns:\n",
    "    A `tuple` `(labels, features)`:\n",
    "      features: A dict of tensors representing the features\n",
    "      labels: A tensor with the corresponding labels.\n",
    "    \"\"\"\n",
    "    features = {}\n",
    "    \n",
    "    #loop through five times to capture each hero on each team\n",
    "    for i in range(5):\n",
    "        #64 bit int for hero\n",
    "        features[\"radiant_hero\"+str(i)]=tf.io.FixedLenFeature(1, dtype=tf.int64)\n",
    "        #there are 4 pieces of info for a hero in LOL\n",
    "        features[\"radiant_hero_info\"+str(i)]=tf.io.FixedLenFeature(4, dtype=tf.float32) \n",
    "        #there are 6 possible tags for a hero in LOL\n",
    "        features[\"radiant_hero_tags\"+str(i)] =tf.io.FixedLenFeature(6, dtype=tf.int64) \n",
    "        #there are 14 stats after removing mana and crit(broken) in LOL\n",
    "        features[\"radiant_hero_stats\"+str(i)] =tf.io.FixedLenFeature(14, dtype=tf.float32) \n",
    "        \n",
    "        features[\"dire_hero\"+str(i)] =tf.io.FixedLenFeature(1, dtype=tf.int64) \n",
    "        features[\"dire_hero_info\"+str(i)] =tf.io.FixedLenFeature(4, dtype=tf.float32) \n",
    "        features[\"dire_hero_tags\"+str(i)] =tf.io.FixedLenFeature(6, dtype=tf.int64) \n",
    "        features[\"dire_hero_stats\"+str(i)] =tf.io.FixedLenFeature(14, dtype=tf.float32) \n",
    " \n",
    "    #there are 11 different regions (at least in my most current dataset)\n",
    "    features[\"region\"] = tf.io.FixedLenFeature(11, dtype=tf.int64)\n",
    "    features[\"skill_level\"] = tf.io.FixedLenFeature(2, dtype=tf.int64)\n",
    "    features[\"targets\"] = tf.io.FixedLenFeature(1, dtype=tf.int64)\n",
    "                \n",
    "    parsed_features = tf.io.parse_single_example(example_proto, features)\n",
    "    num_heroes=len(hero_vocab)\n",
    "    feature_dict={}\n",
    "    for i in range(5):\n",
    "        feature_dict['radiant_hero'+str(i)]=tf.one_hot(parsed_features['radiant_hero'+str(i)],\n",
    "                                                    num_heroes)\n",
    "        feature_dict['radiant_hero_info'+str(i)]=parsed_features['radiant_hero_info'+str(i)]\n",
    "        feature_dict['radiant_hero_tags'+str(i)]=parsed_features['radiant_hero_tags'+str(i)]\n",
    "        feature_dict['radiant_hero_stats'+str(i)]=parsed_features['radiant_hero_stats'+str(i)]\n",
    "        feature_dict['dire_hero'+str(i)]=tf.one_hot(parsed_features['dire_hero'+str(i)],\n",
    "                                                 num_heroes)\n",
    "        feature_dict['dire_hero_info'+str(i)]=parsed_features['dire_hero_info'+str(i)]\n",
    "        feature_dict['dire_hero_tags'+str(i)]=parsed_features['dire_hero_tags'+str(i)]\n",
    "        feature_dict['dire_hero_stats'+str(i)]=parsed_features['dire_hero_stats'+str(i)]\n",
    "\n",
    "    feature_dict['region'] = parsed_features['region']\n",
    "    feature_dict['skill_level']= parsed_features['skill_level']\n",
    "    target = parsed_features['targets']\n",
    "    \n",
    "    return feature_dict, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the parse function worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-14T21:50:36.696460Z",
     "start_time": "2020-03-14T21:50:35.854571Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create the Dataset object.\n",
    "ds = tf.data.TFRecordDataset(os.path.join('LOL_data',\n",
    "                                          'mix_tier',\n",
    "                                          'lol_training_data',\n",
    "                                          'blue_win_extra_info_dota2_compat_lol_training_data.tfrecords'),\n",
    "                                          compression_type=\"GZIP\")\n",
    "# Map features and labels with the parse function.\n",
    "ds = ds.map(_parse_function_extra_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-14T21:50:38.414362Z",
     "start_time": "2020-03-14T21:50:36.699650Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'radiant_hero0': <tf.Tensor: shape=(1, 144), dtype=float32, numpy=\n",
      "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)>, 'radiant_hero_info0': <tf.Tensor: shape=(4,), dtype=float32, numpy=array([-0.5421847 ,  0.60387725,  0.5744302 , -0.83660585], dtype=float32)>, 'radiant_hero_tags0': <tf.Tensor: shape=(6,), dtype=int64, numpy=array([0, 1, 0, 0, 0, 1])>, 'radiant_hero_stats0': <tf.Tensor: shape=(14,), dtype=float32, numpy=\n",
      "array([ 0.42598218,  0.2463295 ,  1.1205487 ,  0.29334182,  0.04125398,\n",
      "        0.67033505,  0.9421065 , -1.0051228 , -0.9286367 ,  0.86505586,\n",
      "        0.27659377, -0.42359763, -0.25851277, -0.64119685], dtype=float32)>, 'dire_hero0': <tf.Tensor: shape=(1, 144), dtype=float32, numpy=\n",
      "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)>, 'dire_hero_info0': <tf.Tensor: shape=(4,), dtype=float32, numpy=array([-0.5421847 , -0.84542817,  1.309701  ,  0.62660766], dtype=float32)>, 'dire_hero_tags0': <tf.Tensor: shape=(6,), dtype=int64, numpy=array([0, 0, 1, 0, 1, 0])>, 'dire_hero_stats0': <tf.Tensor: shape=(14,), dtype=float32, numpy=\n",
      "array([-0.6172217 ,  0.3961561 , -1.4883279 , -1.9365329 , -1.0195627 ,\n",
      "       -3.4821496 , -1.0451494 ,  1.0384731 ,  0.23798215, -0.68045336,\n",
      "       -3.1581135 , -1.0910345 ,  1.2804064 ,  0.2749088 ], dtype=float32)>, 'radiant_hero1': <tf.Tensor: shape=(1, 144), dtype=float32, numpy=\n",
      "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)>, 'radiant_hero_info1': <tf.Tensor: shape=(4,), dtype=float32, numpy=array([ 1.2735037 , -1.32853   , -1.6313819 ,  0.62660766], dtype=float32)>, 'radiant_hero_tags1': <tf.Tensor: shape=(6,), dtype=int64, numpy=array([1, 0, 0, 0, 0, 0])>, 'radiant_hero_stats1': <tf.Tensor: shape=(14,), dtype=float32, numpy=\n",
      "array([ 0.79110354, -0.5028035 ,  1.1205487 ,  0.29334182,  0.04125398,\n",
      "        0.67033505,  0.9421065 , -1.0051228 ,  0.23798215, -0.06224968,\n",
      "        0.6095433 ,  0.24383926,  1.0341793 ,  0.08058337], dtype=float32)>, 'dire_hero1': <tf.Tensor: shape=(1, 144), dtype=float32, numpy=\n",
      "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)>, 'dire_hero_info1': <tf.Tensor: shape=(4,), dtype=float32, numpy=array([ 0.910366  ,  0.12077545, -0.89611113,  0.13886979], dtype=float32)>, 'dire_hero_tags1': <tf.Tensor: shape=(6,), dtype=int64, numpy=array([1, 1, 0, 0, 0, 0])>, 'dire_hero_stats1': <tf.Tensor: shape=(14,), dtype=float32, numpy=\n",
      "array([ 0.44684625, -0.5028035 ,  1.1205487 ,  0.4423976 ,  0.46558067,\n",
      "        0.67033505,  0.9421065 , -1.0051228 ,  0.52963686,  0.24685217,\n",
      "        1.6383574 , -0.08987918,  0.6648387 ,  0.08058337], dtype=float32)>, 'radiant_hero2': <tf.Tensor: shape=(1, 144), dtype=float32, numpy=\n",
      "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)>, 'radiant_hero_info2': <tf.Tensor: shape=(4,), dtype=float32, numpy=array([-1.6315978 ,  0.60387725,  0.9420656 , -2.2998195 ], dtype=float32)>, 'radiant_hero_tags2': <tf.Tensor: shape=(6,), dtype=int64, numpy=array([0, 0, 1, 0, 1, 0])>, 'radiant_hero_stats2': <tf.Tensor: shape=(14,), dtype=float32, numpy=\n",
      "array([ 0.16518119,  0.2463295 , -0.8361087 , -0.75004876,  0.67774403,\n",
      "       -0.75920886, -1.0451494 ,  0.6552989 , -0.636982  , -1.6077589 ,\n",
      "       -0.55578005,  0.41069847, -1.1449301 , -0.64119685], dtype=float32)>, 'dire_hero2': <tf.Tensor: shape=(1, 144), dtype=float32, numpy=\n",
      "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)>, 'dire_hero_info2': <tf.Tensor: shape=(4,), dtype=float32, numpy=array([ 0.910366  , -1.32853   , -0.16084047, -2.2998195 ], dtype=float32)>, 'dire_hero_tags2': <tf.Tensor: shape=(6,), dtype=int64, numpy=array([0, 0, 0, 1, 0, 0])>, 'dire_hero_stats2': <tf.Tensor: shape=(14,), dtype=float32, numpy=\n",
      "array([-0.33034065,  0.3961561 , -1.4883279 , -0.3028814 , -1.0195627 ,\n",
      "       -0.75920886, -1.0451494 ,  1.1661979 , -1.6577736 , -0.06224968,\n",
      "       -1.5546286 , -0.92417526,  0.6648387 ,  0.21938726], dtype=float32)>, 'radiant_hero3': <tf.Tensor: shape=(1, 144), dtype=float32, numpy=\n",
      "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)>, 'radiant_hero_info3': <tf.Tensor: shape=(4,), dtype=float32, numpy=array([ 0.910366  , -1.32853   , -1.2637465 ,  0.13886979], dtype=float32)>, 'radiant_hero_tags3': <tf.Tensor: shape=(6,), dtype=int64, numpy=array([0, 0, 0, 1, 0, 0])>, 'radiant_hero_stats3': <tf.Tensor: shape=(14,), dtype=float32, numpy=\n",
      "array([-1.8951465 ,  0.3961561 , -1.4883279 , -0.3028814 ,  0.04125398,\n",
      "       -0.75920886, -1.0451494 ,  1.6770968 , -1.8036009 , -0.68045336,\n",
      "       -0.22283052, -0.6238287 ,  1.895974  , -0.64119685], dtype=float32)>, 'dire_hero3': <tf.Tensor: shape=(1, 144), dtype=float32, numpy=\n",
      "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)>, 'dire_hero_info3': <tf.Tensor: shape=(4,), dtype=float32, numpy=array([-0.5421847 , -0.36232635, -0.16084047,  1.6020833 ], dtype=float32)>, 'dire_hero_tags3': <tf.Tensor: shape=(6,), dtype=int64, numpy=array([0, 0, 1, 0, 1, 0])>, 'dire_hero_stats3': <tf.Tensor: shape=(14,), dtype=float32, numpy=\n",
      "array([-0.48682123,  0.0965029 , -0.8361087 ,  0.5914534 ,  1.1020707 ,\n",
      "       -0.75920886, -1.0451494 ,  0.91074836,  0.52963686, -0.68045336,\n",
      "       -1.2216791 , -0.42359763, -0.5662966 , -0.64119685], dtype=float32)>, 'radiant_hero4': <tf.Tensor: shape=(1, 144), dtype=float32, numpy=\n",
      "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)>, 'radiant_hero_info4': <tf.Tensor: shape=(4,), dtype=float32, numpy=array([-0.5421847 ,  0.60387725,  0.20679489,  0.13886979], dtype=float32)>, 'radiant_hero_tags4': <tf.Tensor: shape=(6,), dtype=int64, numpy=array([0, 1, 0, 0, 0, 1])>, 'radiant_hero_stats4': <tf.Tensor: shape=(14,), dtype=float32, numpy=\n",
      "array([ 0.5949812 , -0.35297692, -1.4883279 ,  1.3367324 ,  0.57166237,\n",
      "        0.67033505,  0.9421065 , -0.7496733 ,  1.1129464 , -0.68045336,\n",
      "        0.27659377,  0.07698004, -1.7974318 ,  1.6074262 ], dtype=float32)>, 'dire_hero4': <tf.Tensor: shape=(1, 144), dtype=float32, numpy=\n",
      "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)>, 'dire_hero_info4': <tf.Tensor: shape=(4,), dtype=float32, numpy=array([-0.5421847 ,  0.60387725,  0.5744302 , -0.83660585], dtype=float32)>, 'dire_hero_tags4': <tf.Tensor: shape=(6,), dtype=int64, numpy=array([0, 1, 0, 0, 0, 0])>, 'dire_hero_stats4': <tf.Tensor: shape=(14,), dtype=float32, numpy=\n",
      "array([-0.6172217 , -1.5515897 , -1.4883279 , -0.75004876,  0.57166237,\n",
      "        0.67033505,  0.9421065 , -0.7496733 , -1.5119462 , -2.2259626 ,\n",
      "        0.27659377,  2.9135869 , -0.32006952, -1.3074555 ], dtype=float32)>, 'region': <tf.Tensor: shape=(11,), dtype=int64, numpy=array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0])>, 'skill_level': <tf.Tensor: shape=(2,), dtype=int64, numpy=array([1, 0])>}, <tf.Tensor: shape=(1,), dtype=int64, numpy=array([1])>)\n"
     ]
    }
   ],
   "source": [
    "ds = ds.shuffle(10000)\n",
    "print(next(iter(ds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Input functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-14T21:50:43.030094Z",
     "start_time": "2020-03-14T21:50:43.023907Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create an input_fn that parses the tf.Examples from the given files,\n",
    "# and split them into features and targets.\n",
    "def _input_fn_extra_info(input_filenames, num_epochs=None, \n",
    "              shuffle=True, batch_size=50,compression_type=\"\"):\n",
    "   \n",
    "   # Same code as above; create a dataset and map features and labels.\n",
    "    ds = tf.data.TFRecordDataset(input_filenames,compression_type=compression_type)\n",
    "    ds = ds.map(_parse_function_extra_info)\n",
    "\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(10000)\n",
    "    ds = ds.batch(batch_size)\n",
    "    ds = ds.repeat()\n",
    "    \n",
    "    # Return the dataset.\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define and train the linear model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### various iterations of linear models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-14T21:50:53.408427Z",
     "start_time": "2020-03-14T21:50:53.392894Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#define the linear model with no feature columns\n",
    "def define_linear_model_hero_only(vocab_len,\n",
    "                                   embedding_dims):\n",
    "    '''Function to define simple keras linear model\n",
    "    \n",
    "    Args: \n",
    "        vocab_len: An `int` specifying the number of category of the categorical input\n",
    "        embedding_dims: An `list` of `int` specifying the number of dimensions in\n",
    "            the embedding layer\n",
    "    Returns:\n",
    "        model: A uncompiled `tf.keras.model`\n",
    "    '''\n",
    "    \n",
    "    ##define hero processing layers\n",
    "    #embed hero with dense because shared embedding layers are broken\n",
    "    dense_hero = tf.keras.layers.Dense(embedding_dims,activation='linear')\n",
    "    \n",
    "    hero_input=[]\n",
    "    rad_hero_output=[]\n",
    "    dire_hero_output=[]\n",
    "    #process all heroes in same way\n",
    "    for i in range(5):\n",
    "        #add radiant hero to hero_input list and process with\n",
    "        #    embed_hero layer\n",
    "        hero_input.append(tf.keras.Input(shape=(1,len(hero_vocab),),\n",
    "                                         name='radiant_hero'+str(i)))\n",
    "        x_rh = dense_hero(hero_input[-1])        \n",
    "        x_rh = tf.keras.layers.Flatten()(x_rh)\n",
    "        #append radiant outputs for summing\n",
    "        rad_hero_output.append(x_rh)\n",
    "        \n",
    "        #add dire hero to hero_input list and process with\n",
    "        #    embed_hero layer\n",
    "        hero_input.append(tf.keras.Input(shape=(1,len(hero_vocab),),\n",
    "                                         name='dire_hero'+str(i)))\n",
    "        x_dh = dense_hero(hero_input[-1])\n",
    "        x_dh = tf.keras.layers.Flatten()(x_dh)\n",
    "        #append dire outputs for summing\n",
    "        dire_hero_output.append(x_dh)\n",
    "    #sum hero outputs to erase ordering information and get ave team vector\n",
    "    rad_hero_sum = tf.keras.layers.Add()(rad_hero_output)\n",
    "    \n",
    "    dire_hero_sum = tf.keras.layers.Add()(dire_hero_output)\n",
    "    \n",
    "    #define skill input layer\n",
    "    skill = tf.keras.Input(shape=(2,),name='skill_level')\n",
    "    x_skill = tf.keras.layers.Dense(1,activation='linear')(skill)\n",
    "    \n",
    "    #define region input layer\n",
    "    region = tf.keras.Input(shape=(11,),name='region')\n",
    "    x_region = tf.keras.layers.Dense(1,activation='linear')(region)\n",
    "    \n",
    "    # Add a dnn layer to map the average of the embedded vectors of each team\n",
    "    #   to a single vector for each team\n",
    "    x = tf.keras.layers.concatenate([rad_hero_sum,dire_hero_sum,x_skill,x_region])\n",
    "    \n",
    "    #Adds output layer with sigmoid activation for prediction\n",
    "    win_predict = tf.keras.layers.Dense(1,activation='sigmoid')(x)\n",
    "    model = tf.keras.Model(inputs=[hero_input,skill,region],\n",
    "                           outputs=win_predict,name=\"radiant_win\")\n",
    "    #tf.keras.utils.plot_model(model, show_shapes=False)\n",
    "    #model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-14T22:04:18.126052Z",
     "start_time": "2020-03-14T22:04:18.100479Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#define the linear model with no feature columns\n",
    "def define_linear_model_extra_info(vocab_len,\n",
    "                                   embedding_dims):\n",
    "    '''Function to define simple keras linear model\n",
    "    \n",
    "    Args: \n",
    "        vocab_len: An `int` specifying the number of category of the categorical input\n",
    "        embedding_dims: An `list` of `int`s specifying the number of dimensions\n",
    "            in the input layers\n",
    "    Returns:\n",
    "        model: A uncompiled `tf.keras.model`\n",
    "    '''\n",
    "    \n",
    "    ##DEFINE HERO PROCESSING LAYERS\n",
    "    #embed hero with dense because shared embedding layers are broken\n",
    "    dense_hero = tf.keras.layers.Dense(embedding_dims[0],activation='linear')\n",
    "    #process info into num of values specified by dense outputs value\n",
    "    dense_hero_info = tf.keras.layers.Dense(embedding_dims[1],activation='linear')\n",
    "    #process tags into num of values specified by dense outputs value\n",
    "    dense_hero_tags = tf.keras.layers.Dense(embedding_dims[2],activation='linear')\n",
    "    #process stats into num of values specified by dense outputs value\n",
    "    dense_hero_stats = tf.keras.layers.Dense(embedding_dims[3],activation='linear')\n",
    "\n",
    "    #process hero embed, dense_tags, and dense_info output into num of outputs \n",
    "    #    half of total embedding dims\n",
    "    \n",
    "    dense_hero_total = tf.keras.layers.Dense(sum(embedding_dims)/2,activation='linear')\n",
    "    \n",
    "    hero_input=[]\n",
    "    rad_hero_output=[]\n",
    "    dire_hero_output=[]\n",
    "    #process all heroes in same way\n",
    "    for i in range(5):\n",
    "        #add radiant hero to hero_input list and process with\n",
    "        #    embed_hero layer\n",
    "        hero_input.append(tf.keras.Input(shape=(1,len(hero_vocab),),\n",
    "                                         name='radiant_hero'+str(i)))\n",
    "        x_rh = dense_hero(hero_input[-1])        \n",
    "        x_rh = tf.keras.layers.Flatten()(x_rh)\n",
    "        #add radiant hero info to hero_input list and process with\n",
    "        #    dense_info layer\n",
    "        hero_input.append(tf.keras.Input(shape=(4,), #4 info types\n",
    "                                         name='radiant_hero_info'+str(i)))\n",
    "        x_rhi = dense_hero_info(hero_input[-1])\n",
    "        #add radiant hero tags to hero_input list and process with\n",
    "        #    dense_tags layer\n",
    "        hero_input.append(tf.keras.Input(shape=(6,), #6 tag types\n",
    "                                         name='radiant_hero_tags'+str(i)))\n",
    "        x_rht = dense_hero_tags(hero_input[-1])        \n",
    "        #add radiant hero stats to hero_input list and process with\n",
    "        #    dense_stats layer\n",
    "        hero_input.append(tf.keras.Input(shape=(14,), #14 stat types\n",
    "                                         name='radiant_hero_stats'+str(i)))\n",
    "        x_rhs = dense_hero_stats(hero_input[-1])\n",
    "        #append output of hero layers to rad_out_layer for summing later\n",
    "        x_rhtot = tf.keras.layers.concatenate([x_rh,x_rhi,x_rht,x_rhs])\n",
    "        rad_hero_output.append(dense_hero_total(x_rhtot))\n",
    "        #add dire hero to hero_input list and process with\n",
    "        #    embed_hero layer\n",
    "        hero_input.append(tf.keras.Input(shape=(1,len(hero_vocab),),\n",
    "                                         name='dire_hero'+str(i)))\n",
    "        x_dh = dense_hero(hero_input[-1])\n",
    "        x_dh = tf.keras.layers.Flatten()(x_dh)\n",
    "        #add dire hero info to hero_input list and process with\n",
    "        #    dense_info layer       \n",
    "        hero_input.append(tf.keras.Input(shape=(4,),#4 info types\n",
    "                                         name='dire_hero_info'+str(i)))\n",
    "        x_dhi = dense_hero_info(hero_input[-1])\n",
    "        #add dire hero tags to hero_input list and process with\n",
    "        #    dense_tags layer\n",
    "        hero_input.append(tf.keras.Input(shape=(6,),#6 tag types\n",
    "                                         name='dire_hero_tags'+str(i)))\n",
    "        x_dht = dense_hero_tags(hero_input[-1])\n",
    "        #add dire hero stats to hero_input list and process with\n",
    "        #    dense_stats layer\n",
    "        hero_input.append(tf.keras.Input(shape=(14,), #14 stat types\n",
    "                                         name='dire_hero_stats'+str(i)))\n",
    "        x_dhs = dense_hero_stats(hero_input[-1])\n",
    "        #append output of hero layers to dire_out layer for summing later\n",
    "        x_dhtot = tf.keras.layers.concatenate([x_dh,x_dhi,x_dht,x_dhs])\n",
    "        dire_hero_output.append(dense_hero_total(x_dhtot))\n",
    "    #sum hero outputs to erase ordering information and get ave team vector\n",
    "    rad_hero_sum = tf.keras.layers.Add()(rad_hero_output)\n",
    "    dire_hero_sum = tf.keras.layers.Add()(dire_hero_output)    \n",
    "    \n",
    "    #define skill input layer\n",
    "    skill = tf.keras.Input(shape=(2,),name='skill_level')\n",
    "    x_skill = tf.keras.layers.Dense(1,activation='linear')(skill)\n",
    "    \n",
    "    #define region input layer\n",
    "    region = tf.keras.Input(shape=(11,),name='region')\n",
    "    x_region = tf.keras.layers.Dense(1,activation='linear')(region)\n",
    "    \n",
    "    # Add a dnn layer to map the average of the embedded vectors of each team\n",
    "    #   to a single vector for each team\n",
    "    x = tf.keras.layers.concatenate([rad_hero_sum,dire_hero_sum,x_skill,x_region])\n",
    "    \n",
    "    #Adds output layer with sigmoid activation for prediction\n",
    "    win_predict = tf.keras.layers.Dense(1,activation='sigmoid')(x)\n",
    "    model = tf.keras.Model(inputs=[hero_input,skill,region],\n",
    "                           outputs=win_predict,name=\"radiant_win\")\n",
    "    tf.keras.utils.plot_model(model, show_shapes=True)\n",
    "    #model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T21:41:03.987788Z",
     "start_time": "2020-03-10T21:41:03.956315Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#define the linear model with no feature columns\n",
    "def define_dnn_model_info_tags(vocab_len,\n",
    "                                embedding_dims,\n",
    "                                hidden_units_heroes,\n",
    "                                hidden_units_out):\n",
    "    '''Function to define simple keras linear model\n",
    "    \n",
    "    Args: \n",
    "        vocab_len: An `int` specifying the number of category of the \n",
    "            categorical input\n",
    "        embedding_dims: An `list` of `int` specifying the number of dimensions in \n",
    "            the embedding layer\n",
    "        hidden_units_heroes: A `list` specifying size and number of hidden \n",
    "            units in hero input layer\n",
    "        hidden_units_heroes: A `list` specifying size and number of hidden \n",
    "            units in output layer\n",
    "    Returns: \n",
    "        model: A uncompiled `tf.keras.model`\n",
    "    '''\n",
    "    \n",
    "    ##DEFINE HERO PROCESSING LAYERS\n",
    "    #embed hero with dense because shared embedding layers are broken\n",
    "    dense_hero = tf.keras.layers.Dense(embedding_dims[0],activation='linear')\n",
    "    #process info into num of values specified by dense outputs value\n",
    "    dense_hero_info = tf.keras.layers.Dense(embedding_dims[1],activation='linear')\n",
    "    #process tags into num of values specified by dense outputs value\n",
    "    dense_hero_tags = tf.keras.layers.Dense(embedding_dims[2],activation='linear')\n",
    "    #process hero embed, dense_tags, and dense_info output into some num of outputs\n",
    "    dense_hero_out_list = []\n",
    "    for unit in hidden_units_heroes:\n",
    "        dense_hero_out_list.append(tf.keras.layers.Dense(unit,\n",
    "                                                         activation='relu'))\n",
    "    \n",
    "    hero_input=[]\n",
    "    rad_hero_output=[]\n",
    "    dire_hero_output=[]\n",
    "    #process all heroes in same way\n",
    "    for i in range(5):\n",
    "        #add radiant hero to hero_input list and process with\n",
    "        #    embed_hero layer\n",
    "        hero_input.append(tf.keras.Input(shape=(1,vocab_len,),\n",
    "                                         name='radiant_hero'+str(i)))\n",
    "        x_rh = dense_hero(hero_input[-1])        \n",
    "        x_rh = tf.keras.layers.Flatten()(x_rh)\n",
    "        #add radiant hero info to hero_input list and process with\n",
    "        #    dense_info layer\n",
    "        hero_input.append(tf.keras.Input(shape=(4,), #4 info types\n",
    "                                         name='radiant_hero_info'+str(i)))\n",
    "        x_rhi = dense_hero_info(hero_input[-1])\n",
    "        #add radiant hero tags to hero_input list and process with\n",
    "        #    dense_tags layer\n",
    "        hero_input.append(tf.keras.Input(shape=(6,), #6 tag types\n",
    "                                         name='radiant_hero_tags'+str(i)))\n",
    "        x_rht = dense_hero_tags(hero_input[-1])        \n",
    "        #append output of hero layers to rad_out_layer for summing later\n",
    "        x_rhtot = tf.keras.layers.concatenate([x_rh,x_rhi,x_rht])\n",
    "        #put total hero info into hidden layers\n",
    "        for layer in dense_hero_out_list:\n",
    "            x_rhtot=layer(x_rhtot)\n",
    "        #append to rad_hero_output list\n",
    "        rad_hero_output.append(x_rhtot)\n",
    "        \n",
    "        #add dire hero to hero_input list and process with\n",
    "        #    embed_hero layer\n",
    "        hero_input.append(tf.keras.Input(shape=(1,vocab_len,),\n",
    "                                         name='dire_hero'+str(i)))\n",
    "        x_dh = dense_hero(hero_input[-1])\n",
    "        x_dh = tf.keras.layers.Flatten()(x_dh)\n",
    "        #add dire hero info to hero_input list and process with\n",
    "        #    dense_info layer       \n",
    "        hero_input.append(tf.keras.Input(shape=(4,),#4 info types\n",
    "                                         name='dire_hero_info'+str(i)))\n",
    "        x_dhi = dense_hero_info(hero_input[-1])\n",
    "        #add dire hero tags to hero_input list and process with\n",
    "        #    dense_tags layer\n",
    "        hero_input.append(tf.keras.Input(shape=(6,),#6 tag types\n",
    "                                         name='dire_hero_tags'+str(i)))\n",
    "        x_dht = dense_hero_tags(hero_input[-1])\n",
    "        #append output of hero layers to dire_out layer for summing later\n",
    "        x_dhtot = tf.keras.layers.concatenate([x_dh,x_dhi,x_dht])\n",
    "        #put total hero info into hidden layers\n",
    "        for layer in dense_hero_out_list:\n",
    "            x_dhtot=layer(x_dhtot)\n",
    "        dire_hero_output.append(x_dhtot)\n",
    "    \n",
    "    #sum hero outputs to erase ordering information and get ave team vector\n",
    "    rad_hero_sum = tf.keras.layers.Add()(rad_hero_output)\n",
    "    dire_hero_sum = tf.keras.layers.Add()(dire_hero_output)    \n",
    "    \n",
    "    #define skill input layer\n",
    "    skill = tf.keras.Input(shape=(2,),name='skill_level')\n",
    "    region = tf.keras.Input(shape=(11,),name='region')\n",
    "    \n",
    "    # Add a dnn layer to map the average of the embedded vectors of each team\n",
    "    #   to a single vector for each team\n",
    "    x = tf.keras.layers.concatenate([rad_hero_sum,dire_hero_sum,skill,region])\n",
    "    for unit in hidden_units_out:\n",
    "        x = tf.keras.layers.Dense(unit,activation='relu')(x)\n",
    "        \n",
    "    #Adds output layer with sigmoid activation for prediction\n",
    "    win_predict = tf.keras.layers.Dense(1,activation='sigmoid')(x)\n",
    "    model = tf.keras.Model(inputs=[hero_input,skill],\n",
    "                           outputs=win_predict,name=\"radiant_win\")\n",
    "    tf.keras.utils.plot_model(model, show_shapes=False)\n",
    "    #model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T21:41:05.005109Z",
     "start_time": "2020-03-10T21:41:04.972264Z"
    },
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "#define the linear model with no feature columns\n",
    "def define_dnn_model_extra_info(vocab_len,\n",
    "                                embedding_dims,\n",
    "                                hidden_units_heroes,\n",
    "                                hidden_units_out):\n",
    "    '''Function to define simple keras linear model\n",
    "    \n",
    "    Args: \n",
    "        vocab_len: An `int` specifying the number of category of the \n",
    "            categorical input\n",
    "        embedding_dims: An `list` of `int` specifying the numbers of dimensions in \n",
    "            the embedding layers\n",
    "        hidden_units_heroes: A `list` specifying size and number of hidden \n",
    "            units in hero input layer\n",
    "        hidden_units_heroes: A `list` specifying size and number of hidden \n",
    "            units in output layer\n",
    "    Returns: \n",
    "        model: A uncompiled `tf.keras.model`\n",
    "    '''\n",
    "    \n",
    "    ##DEFINE HERO PROCESSING LAYERS\n",
    "    #embed hero with dense because shared embedding layers are broken\n",
    "    dense_hero = tf.keras.layers.Dense(embedding_dims[0],activation='linear')\n",
    "    #process info into num of values specified by dense outputs value\n",
    "    dense_hero_info = tf.keras.layers.Dense(embedding_dims[1],activation='linear')\n",
    "    #process tags into num of values specified by dense outputs value\n",
    "    dense_hero_tags = tf.keras.layers.Dense(embedding_dims[2],activation='linear')\n",
    "    #process stats into num of values specified by dense outputs value\n",
    "    dense_hero_stats = tf.keras.layers.Dense(embedding_dims[3],activation='linear')\n",
    "    \n",
    "    #process hero embed, dense_tags, and dense_info output into some num of outputs\n",
    "    dense_hero_out_list = []\n",
    "    for unit in hidden_units_heroes:\n",
    "        dense_hero_out_list.append(tf.keras.layers.Dense(unit,\n",
    "                                                         activation='relu'))\n",
    "    \n",
    "    hero_input=[]\n",
    "    rad_hero_output=[]\n",
    "    dire_hero_output=[]\n",
    "    #process all heroes in same way\n",
    "    for i in range(5):\n",
    "        #add radiant hero to hero_input list and process with\n",
    "        #    embed_hero layer\n",
    "        hero_input.append(tf.keras.Input(shape=(1,vocab_len,),\n",
    "                                         name='radiant_hero'+str(i)))\n",
    "        x_rh = dense_hero(hero_input[-1])        \n",
    "        x_rh = tf.keras.layers.Flatten()(x_rh)\n",
    "        #add radiant hero info to hero_input list and process with\n",
    "        #    dense_info layer\n",
    "        hero_input.append(tf.keras.Input(shape=(4,), #4 info types\n",
    "                                         name='radiant_hero_info'+str(i)))\n",
    "        x_rhi = dense_hero_info(hero_input[-1])\n",
    "        #add radiant hero tags to hero_input list and process with\n",
    "        #    dense_tags layer\n",
    "        hero_input.append(tf.keras.Input(shape=(6,), #6 tag types\n",
    "                                         name='radiant_hero_tags'+str(i)))\n",
    "        x_rht = dense_hero_tags(hero_input[-1])        \n",
    "        #add radiant hero stats to hero_input list and process with\n",
    "        #    dense_stats layer\n",
    "        hero_input.append(tf.keras.Input(shape=(14,), #14 stat types\n",
    "                                         name='radiant_hero_stats'+str(i)))\n",
    "        x_rhs = dense_hero_stats(hero_input[-1])\n",
    "        #append output of hero layers to rad_out_layer for summing later\n",
    "        x_rhtot = tf.keras.layers.concatenate([x_rh,x_rhi,x_rht,x_rhs])\n",
    "        #put total hero info into hidden layers\n",
    "        for layer in dense_hero_out_list:\n",
    "            x_rhtot=layer(x_rhtot)\n",
    "        #append to rad_hero_output list\n",
    "        rad_hero_output.append(x_rhtot)\n",
    "        \n",
    "        #add dire hero to hero_input list and process with\n",
    "        #    embed_hero layer\n",
    "        hero_input.append(tf.keras.Input(shape=(1,vocab_len,),\n",
    "                                         name='dire_hero'+str(i)))\n",
    "        x_dh = dense_hero(hero_input[-1])\n",
    "        x_dh = tf.keras.layers.Flatten()(x_dh)\n",
    "        #add dire hero info to hero_input list and process with\n",
    "        #    dense_info layer       \n",
    "        hero_input.append(tf.keras.Input(shape=(4,),#4 info types\n",
    "                                         name='dire_hero_info'+str(i)))\n",
    "        x_dhi = dense_hero_info(hero_input[-1])\n",
    "        #add dire hero tags to hero_input list and process with\n",
    "        #    dense_tags layer\n",
    "        hero_input.append(tf.keras.Input(shape=(6,),#6 tag types\n",
    "                                         name='dire_hero_tags'+str(i)))\n",
    "        x_dht = dense_hero_tags(hero_input[-1])\n",
    "        #add dire hero stats to hero_input list and process with\n",
    "        #    dense_stats layer\n",
    "        hero_input.append(tf.keras.Input(shape=(14,), #14 stat types\n",
    "                                         name='dire_hero_stats'+str(i)))\n",
    "        x_dhs = dense_hero_stats(hero_input[-1])\n",
    "        #append output of hero layers to dire_out layer for summing later\n",
    "        x_dhtot = tf.keras.layers.concatenate([x_dh,x_dhi,x_dht,x_dhs])\n",
    "        #put total hero info into hidden layers\n",
    "        for layer in dense_hero_out_list:\n",
    "            x_dhtot=layer(x_dhtot)\n",
    "        dire_hero_output.append(x_dhtot)\n",
    "    \n",
    "    #sum hero outputs to erase ordering information and get ave team vector\n",
    "    rad_hero_sum = tf.keras.layers.Add()(rad_hero_output)\n",
    "    dire_hero_sum = tf.keras.layers.Add()(dire_hero_output)    \n",
    "    \n",
    "    #define skill, region input layer\n",
    "    skill = tf.keras.Input(shape=(2,),name='skill_level')\n",
    "    region = tf.keras.Input(shape=(11,),name='region')\n",
    "\n",
    "    # Add a dnn layer to map the average of the embedded vectors of each team\n",
    "    #   to a single vector for each team\n",
    "    x = tf.keras.layers.concatenate([rad_hero_sum,dire_hero_sum,skill,region])\n",
    "    for unit in hidden_units_out:\n",
    "        x = tf.keras.layers.Dense(unit,activation='relu')(x)\n",
    "        \n",
    "    #Adds output layer with sigmoid activation for prediction\n",
    "    win_predict = tf.keras.layers.Dense(1,activation='sigmoid')(x)\n",
    "    model = tf.keras.Model(inputs=[hero_input,skill],\n",
    "                           outputs=win_predict,name=\"radiant_win\")\n",
    "    tf.keras.utils.plot_model(model, show_shapes=False)\n",
    "    #model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-14T21:47:27.508963Z",
     "start_time": "2020-03-14T21:47:27.488499Z"
    },
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "#define the linear model with no feature columns\n",
    "def train_model(optimizer,\n",
    "                       model_type,\n",
    "                       vocab_len,\n",
    "                       embedding_dims,\n",
    "                       batch_size,\n",
    "                       epochs,\n",
    "                       training_path,\n",
    "                       validation_path,\n",
    "                       compression_type='',\n",
    "                       temp_log_flag=True,\n",
    "                       hidden_units_heroes=[],\n",
    "                       hidden_units_out=[]):\n",
    "    '''Function to train keras model\n",
    "    \n",
    "    Args: \n",
    "        optimizer: A `tf.keras.optimizer` object to use for the model\n",
    "        vocab_len: An `int` specifying the number of category of the categorical input\n",
    "        embedding_dims: An `int` specifying the number of dimensions in the embedding layer\n",
    "        batch_size: An `int` specifying batch size for each train step\n",
    "        epochs: An `int` number of epochs to train for\n",
    "        training_path: A `string` specifying training file\n",
    "        validation_path: A `string` specifying validatoin file\n",
    "        compression_type: A `string` specifying compression type\n",
    "        temp_log_flag: A `bool` specifying whether to save logs in temp folder\n",
    "    Returns:\n",
    "        history: A `tf.keras.history` object that has loss and other metrics\n",
    "    '''\n",
    "    if model_type=='linear_extra_info':\n",
    "        model = define_linear_model_extra_info(vocab_len,embedding_dims)\n",
    "    elif model_type=='linear_hero_only':\n",
    "        model = define_linear_model_hero_only(vocab_len,embedding_dims)\n",
    "    elif model_type=='dnn_extra_info':\n",
    "        model = define_dnn_model_extra_info(vocab_len,embedding_dims,\n",
    "                                            hidden_units_heroes,\n",
    "                                            hidden_units_out)\n",
    "    elif model_type=='dnn_info_tags':\n",
    "        model = define_dnn_model_info_tags(vocab_len,embedding_dims,\n",
    "                                            hidden_units_heroes,\n",
    "                                            hidden_units_out)\n",
    "    else:\n",
    "        raise KeyError('model_type not found. Got: '+ model_type)\n",
    "        \n",
    "    model.compile(optimizer = optimizer,\n",
    "                  loss = 'binary_crossentropy',\n",
    "                  metrics = ['binary_accuracy'])\n",
    "\n",
    "    ##get embedding weights for returning and saving\n",
    "    #embedding_weights = model.layers[1].get_weights()[0]\n",
    "    \n",
    "    #get datasets from tfrecords and according to input_fn\n",
    "    train_ds = _input_fn_extra_info(training_path,\n",
    "                               batch_size=batch_size,\n",
    "                               compression_type=compression_type,\n",
    "                               shuffle=True)\n",
    "\n",
    "    validation_ds= _input_fn_extra_info(validation_path,\n",
    "                                   batch_size=batch_size,\n",
    "                                   compression_type=compression_type,\n",
    "                                   shuffle=True)\n",
    "\n",
    "    #allow logging in temp directory or directory to be included in git\n",
    "    #  useful if tuning hyperparams or testing\n",
    "    if temp_log_flag:\n",
    "        logdir = os.path.join('..','..','..','tmp_log_dir',\n",
    "                          datetime.now().strftime(\"lol_%Y%m%d-%H%M%S\"))\n",
    "    else:\n",
    "        logdir = os.path.join('log_dir',\n",
    "                          datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "        \n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "    steps_per_epoch=50\n",
    "\n",
    "    history = model.fit(train_ds, \n",
    "                        epochs = epochs,\n",
    "                        steps_per_epoch=steps_per_epoch,\n",
    "                        validation_steps=steps_per_epoch,\n",
    "                        verbose=0,\n",
    "                        validation_data=validation_ds,\n",
    "                        callbacks=[tensorboard_callback]\n",
    "                       )\n",
    "    \n",
    "    #save trained model. This can be used to retrain, predict, \n",
    "    #  or reloaded as a keras model to do more model things.\n",
    "    #Use TF `SavedModel` format so that it can be used in serving\n",
    "    model.save(os.path.join(logdir,'saved_model'),\n",
    "                      save_format='tf')\n",
    "    \n",
    "    #save params for this training to a json in the logdir\n",
    "    hyper = optimizer._hyper\n",
    "    hyper_dict={}\n",
    "    for key,value in hyper.items():\n",
    "        hyper_dict[key]=value.numpy().item()\n",
    "    training_params = dict({'model_type':'single_target_'+model_type,\n",
    "                            'steps':steps_per_epoch*epochs,\n",
    "                            'batch_size':batch_size,\n",
    "                            'embedding_dims':embedding_dims,\n",
    "                            'optimizer':optimizer._name,\n",
    "                            'hyper_parameters':hyper_dict})\n",
    "    if len(hidden_units_heroes)>0 or len(hidden_units_out)>0:\n",
    "        training_params['hidden_units_heroes']=hidden_units_heroes\n",
    "        training_params['hidden_units_out']=hidden_units_out\n",
    "\n",
    "    with open(os.path.join(logdir,'training_params.json'),'w') as fp:\n",
    "        json.dump(training_params,fp)\n",
    "    \n",
    "    ##save embedding in numpy format for later use\n",
    "    ##  no hero_vocab, but that should be ok\n",
    "    #np.save(os.path.join(logdir,'embedding.npy'),embedding_weights)\n",
    "    fig,ax = plt.subplots(1,1,figsize=(1.6*3,3))\n",
    "    plt.plot(history.history['binary_accuracy'])\n",
    "    plt.xlabel('epochs (50 steps per)')\n",
    "    plt.ylabel('binary_accuracy')\n",
    "    plt.show()\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train no feature column win model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-14T21:47:34.179848Z",
     "start_time": "2020-03-14T21:47:34.175721Z"
    }
   },
   "outputs": [],
   "source": [
    "training_file_novocab = os.path.join('LOL_data',\n",
    "                             'mix_tier',\n",
    "                             'lol_training_data',\n",
    "                             'blue_win_extra_info_dota2_compat_lol_training_data.tfrecords')\n",
    "validation_file_novocab = os.path.join('LOL_data',\n",
    "                             'mix_tier',\n",
    "                             'lol_validation_data',\n",
    "                             'blue_win_extra_info_dota2_compat_lol_validation_data.tfrecords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-14T22:04:27.314717Z",
     "start_time": "2020-03-14T22:04:23.649629Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-c3a097c031d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mtraining_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_file_novocab\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mvalidation_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_file_novocab\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             compression_type='GZIP')\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-5b32b19d90f6>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(optimizer, model_type, vocab_len, embedding_dims, batch_size, epochs, training_path, validation_path, compression_type, temp_log_flag, hidden_units_heroes, hidden_units_out)\u001b[0m\n\u001b[1;32m     78\u001b[0m                         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                         \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensorboard_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m                        )\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.002)\n",
    "history = train_model(\n",
    "            optimizer,\n",
    "            model_type='linear_hero_only',\n",
    "            vocab_len=len(champ_vocab),\n",
    "            embedding_dims=2,\n",
    "            batch_size=500, \n",
    "            epochs=50, \n",
    "            training_path=training_file_novocab, \n",
    "            validation_path=validation_file_novocab,\n",
    "            compression_type='GZIP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-14T22:00:06.559358Z",
     "start_time": "2020-03-14T22:00:06.525241Z"
    },
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'define_linear_model_extra_info' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-d623e7d1eeef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mtraining_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_file_novocab\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mvalidation_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_file_novocab\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             compression_type='GZIP')\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-5b32b19d90f6>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(optimizer, model_type, vocab_len, embedding_dims, batch_size, epochs, training_path, validation_path, compression_type, temp_log_flag, hidden_units_heroes, hidden_units_out)\u001b[0m\n\u001b[1;32m     28\u001b[0m     '''\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'linear_extra_info'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefine_linear_model_extra_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_len\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0membedding_dims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'linear_hero_only'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefine_linear_model_hero_only\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_len\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0membedding_dims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'define_linear_model_extra_info' is not defined"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.004)\n",
    "history = train_model(\n",
    "            optimizer,\n",
    "            model_type='linear_extra_info',\n",
    "            vocab_len=len(champ_vocab),\n",
    "            embedding_dims=[3,3,3,3],#hero,info,tags,stats\n",
    "            batch_size=500, \n",
    "            epochs=20, \n",
    "            training_path=training_file_novocab, \n",
    "            validation_path=validation_file_novocab,\n",
    "            compression_type='GZIP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-14T22:00:06.562068Z",
     "start_time": "2020-03-14T21:53:55.001Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.005)\n",
    "history = train_model(\n",
    "            optimizer,\n",
    "            model_type='linear_extra_info',\n",
    "            vocab_len=len(champ_vocab),\n",
    "            embedding_dims=5,\n",
    "            batch_size=500, \n",
    "            epochs=50, \n",
    "            training_path=training_file_novocab, \n",
    "            validation_path=validation_file_novocab,\n",
    "            compression_type='GZIP')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "notify_time": "30",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
